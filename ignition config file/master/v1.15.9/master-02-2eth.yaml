#cloud-config

passwd:
  users:
    - name: admin
      ssh_authorized_keys:
        - "ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA8PF9Cj1svhd8Cb+yFrw9GHA+6j6sq1halwXrVx+m+F49xMrCKV0zpdVJGwEb13U3WDaibhPPHy5dWCeVj7ZxSLDdo510p1NFAMicmWF9CNJ1oQF+uRu8IobaJxrlW00+rYJ4EjRLbFQf3X4OhCkjDcF3KS/uhmpX2niMj5ffcWN4PlglDaahA3YZXEG8BFQxJgmaOgJSq6M34wqTFdhBCC1beQPPtwDE0N4NYNS3lhl8n3Fe84m59DtD+O6xD2EL6II5fkfMqeFYmgi8M9f/kMSCdAWHtaahAFBNSILh5jOiY+OIYL7DSL4sbyjUa7vPGHaXKhfVfiZID0mwyr8Uzw== cent@centos-vm"
      groups:
        - "sudo"
        - "docker"

etcd:
  version: 3.4.3
  client_cert_auth:            true
  peer_client_cert_auth:       true
  trusted_ca_file:             /etc/ssl/certs/ca.pem
  peer_trusted_ca_file:        /etc/ssl/certs/ca.pem
  cert_file:                   /var/lib/etcd/ssl/etcd-node.pem
  key_file:                    /var/lib/etcd/ssl/etcd-node-key.pem
  peer_cert_file:              /var/lib/etcd/ssl/etcd-node.pem
  peer_key_file:               /var/lib/etcd/ssl/etcd-node-key.pem
  advertise_client_urls:       "https://10.9.56.102:2379"
  initial_advertise_peer_urls: "https://10.9.56.102:2380"
  listen_client_urls:          "https://0.0.0.0:2379"
  listen_peer_urls:            "https://10.9.56.102:2380"
  initial_cluster:             manager-01=https://10.9.56.101:2380,manager-02=https://10.9.56.102:2380,manager-03=https://10.9.56.103:2380
  initial_cluster_token:       k8s_etcd
  initial_cluster_state:       new
  auto_compaction_retention:   1
flannel:
  etcd_cafile:    /etc/ssl/certs/ca.pem
  etcd_certfile:  /var/lib/etcd/ssl/etcd-node.pem
  etcd_keyfile:   /var/lib/etcd/ssl/etcd-node-key.pem
  version:        0.11.0
  etcd_prefix:    "/coreos.com/network"
  etcd_endpoints: "https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
  interface:      ens32
locksmith:
  etcd_cafile:     /etc/ssl/certs/ca.pem
  etcd_certfile:   /var/lib/etcd/ssl/etcd-node.pem
  etcd_keyfile:    /var/lib/etcd/ssl/etcd-node-key.pem
  reboot_strategy: "off"
  etcd_endpoints:  "https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
systemd:
  units:
     - name: "settimezone.service"
       enable: true
       contents: |
         [Unit]
         Description=Set the time zone
         [Service]
         ExecStart=/usr/bin/timedatectl set-timezone Asia/Jakarta
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: systemd-timesyncd.service
       mask: true
     - name: ntpd.service
       enable: true
     - name: "locksmithd.service"
       enable: true
       dropins:
        - name: "20-locksmithd-config.conf"
          contents: |
            [Service]
            Environment="LOCKSMITHD_ETCD_CAFILE=/etc/ssl/certs/ca.pem"
            Environment="LOCKSMITHD_ETCD_CERTFILE=/var/lib/etcd/ssl/etcd-node.pem"
            Environment="LOCKSMITHD_ETCD_KEYFILE=/var/lib/etcd/ssl/etcd-node-key.pem"
            Environment="LOCKSMITHD_ENDPOINT=https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
        - name: 40-etcd-lock.conf
          contents: |
            [Service]
            Environment="REBOOT_STRATEGY=off"
     - name: "etcd3.service"
       enable: true
       contents: |
         [Unit]
         Description=etcd3
         [Service]
         Environment="ETCD_NAME=etcd3"
         Environment="ETCD_DATA_DIR=/var/lib/etcd"
         Environment="ETCD_ENABLE_V2=true"
         ExecStart=/usr/bin/rkt run \
           --dns=10.9.35.30 \
           --net=host \
           --inherit-env=true \
           --volume ssl,kind=host,source=/etc/ssl/certs,readOnly=true \
           --volume data,kind=host,source=/var/lib/etcd,readOnly=false \
           --mount volume=ssl,target=/etc/ssl/certs \
           --mount volume=data,target=/var/lib/etcd \
           --insecure-options=image \
           docker://gcr.io/etcd-development/etcd:v3.4.3 \
           -- --peer-client-cert-auth \
           --peer-trusted-ca-file=/etc/ssl/certs/ca.pem \
           --peer-cert-file=/var/lib/etcd/ssl/etcd-node.pem \
           --peer-key-file=/var/lib/etcd/ssl/etcd-node-key.pem \
           --trusted-ca-file=/etc/ssl/certs/ca.pem \
           --cert-file=/var/lib/etcd/ssl/etcd-node.pem \
           --key-file=/var/lib/etcd/ssl/etcd-node-key.pem \
           --client-cert-auth \
           --listen-client-urls https://0.0.0.0:2379 \
           --advertise-client-urls https://10.9.56.102:2379 \
           --listen-peer-urls https://10.9.56.102:2380 \
           --initial-advertise-peer-urls https://10.9.56.102:2380 \
           --log-level info \
           --logger zap \
           --log-outputs stderr \
           --auto-compaction-retention 1
         Restart=on-failure
         RestartSec=10
         [Install]
         WantedBy=multi-user.target
     - name: "etcd-v3-datastore.service"
       enable: true
       contents: |
         [Unit]
         Description=Choose etcd v3 datastore
         After=etcd-member.service
         Requires=etcd-member.service
         [Service]
         ExecStart=/etc/profile.d/etcdctl.sh
         RemainAfterExit=yes
         Type=oneshot
     - name: "locksmith-profile.service"
       enable: true
       contents: |
         [Unit]
         Description=locksmith profile
         [Service]
         ExecStart=/etc/profile.d/locksmithctl.sh
         RemainAfterExit=yes
         Type=oneshot
     - name: "rpcbind.service"
       enable: true
     - name: "rpc-statd.service"
       enable: true
     - name: "flanneld.service"
       enable: true
       dropins:
         - name: "50-ssl.conf"
           contents: |
             [Unit]
             Description=Flannel etcd ssl dir
             Requires=etcd-member.service etcd-v3-datastore.service
             After=etcd-member.service etcd-v3-datastore.service
             [Service]
             Environment="ETCD_SSL_DIR=/var/lib/etcd/ssl"
         - name: "50-network-config.conf"
           contents: |
             [Unit]
             Description=Flannel networking vxlan
             Requires=etcd-member.service etcd-v3-datastore.service
             After=etcd-member.service etcd-v3-datastore.service
             [Service]
             Environment="FLANNEL_IMAGE_TAG=v0.11.0-amd64"
             Environment="FLANNEL_IMAGE_URL=quay.io/coreos/flannel"
             Environment="FLANNEL_ETCD=https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
             Environment="FLANNEL_ETCD_KEY=/coreos.com/network"
             ExecStartPre=ETCDCTL_API=2 /usr/bin/etcdctl --ca-file=/etc/ssl/certs/ca.pem --cert-file=/var/lib/etcd/ssl/etcd-node.pem --key-file=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379" set /coreos.com/network/config '{ "Network":"10.244.0.0/16", "SubnetLen": 24, "SubnetMin": "10.244.0.0", "SubnetMax":"10.244.255.0", "Backend": {"Type": "vxlan"} }'
             
     - name: "docker-tcp.socket"
       enable: true
       contents: |
         [Unit]
         Description=Docker Socket for the API
         [Socket]
         ListenStream=2375
         Service=docker.service
         BindIPv6Only=both
         [Install]
         WantedBy=sockets.target
     - name: "dns.service"
       enable: true
       contents: |
         [Unit]
         Description=storytel/dnsmasq
         Requires=docker.service
         After=docker.service
         [Service]
         Restart=always
         ExecStartPre=-/usr/bin/docker rm dnsmasq
         ExecStart=/usr/bin/docker run --name dnsmasq --net=host \
           -v /etc/dnsmasq:/etc/dnsmasq \
           --cap-add=NET_ADMIN \
           storytel/dnsmasq
         ExecStop=-/usr/bin/docker stop dnsmasq
         ExecStopPost=-/usr/bin/docker rm dnsmasq
         [Install]
         WantedBy=multi-user.target
     - name: "timer-hourly.timer"
       enable: true
       contents: |
         [Unit]
         Description=1440 minutes timer (24 hours)
         [Timer]
         # Time to wait after booting before we run first time
         OnBootSec=5min
         # Time between running each consecutive time
         OnUnitActiveSec=1440min
         Unit=timer-hourly.target
         [Install]
         WantedBy=basic.target
     - name: "timer-hourly.target"
       enable: true
       contents: |
         [Unit]
         Description=1440 minutes timer (24 hours)
         StopWhenUnneeded=yes
     - name: "clean-dangling.service"
       enable: true
       contents: |
         [Unit]
         Description=Remove all dangling docker image layers every 24 hours
         Requires=docker.service
         After=docker.service
         Wants=timer-hourly.timer
         [Service]
         ExecStartPre=-/usr/bin/docker rm -f %p
         ExecStartPre=/usr/bin/docker pull liske/docker-prune:latest
         ExecStart=/usr/bin/docker run \
           -v /var/run/docker.sock:/var/run/docker.sock \
           --name=%p liske/docker-prune:latest image
         ExecStop=/usr/bin/docker stop %p
         ExecStopPost=-/usr/bin/docker rm -f %p
         [Install]
         WantedBy=timer-hourly.target
     - name: "timer-hourly-config.timer"
       enable: true
       contents: |
         [Unit]
         Description=2 minutes timer (120 seconds)
         [Timer]
         # Time to wait after booting before we run first time
         OnBootSec=5min
         # Time between running each consecutive time
         OnUnitActiveSec=2min
         Unit=timer-hourly-config.target
         [Install]
         WantedBy=basic.target
     - name: "timer-hourly-config.target"
       enable: true
       contents: |
         [Unit]
         Description=2 minutes timer (120 seconds)
         StopWhenUnneeded=yes
     - name: "kubectl-config.service"
       enable: true
       contents: |
         [Unit]
         Description=Installs cni tools
         Wants=timer-hourly-config.timer
         [Service]
         ExecStart=sudo /opt/bin/scripts/kubectl-config.sh
         [Install]
         WantedBy=timer-hourly-config.target
     - name: "timer-hourly-octant.timer"
       enable: true
       contents: |
         [Unit]
         Description=60 minutes timer (3600 seconds)
         [Timer]
         # Time to wait after booting before we run first time
         OnBootSec=5min
         # Time between running each consecutive time
         OnUnitActiveSec=60min
         Unit=timer-hourly-octant.target
         [Install]
         WantedBy=basic.target
     - name: "timer-hourly-octant.target"
       enable: true
       contents: |
         [Unit]
         Description=60 minutes timer (3600 seconds)
         StopWhenUnneeded=yes
     - name: "refresh-octant.service"
       enable: true
       contents: |
         [Unit]
         Description=Installs cni tools
         Wants=timer-hourly-octant.timer
         [Service]
         ExecStart=sudo /opt/bin/scripts/refresh-octant.sh
         [Install]
         WantedBy=timer-hourly-octant.target
     - name: "vmware-tools.service"
       enable: true
       contents: |
         [Unit]
         Description=VMWare Tools
         Requires=docker.service
         After=docker.service
         [Service]
         Restart=always
         ExecStartPre=-/usr/bin/docker rm vmware-tools
         ExecStart=/usr/bin/docker run --net=host --privileged --name vmware-tools sergeyzh/vmware-tools
         ExecStop=-/usr/bin/docker stop vmware-tools
         ExecStopPost=-/usr/bin/docker rm vmware-tools
         [Install]
         WantedBy=multi-user.target
     - name: "setup-network-environment.service"
       enable: true
       contents: |
         [Unit]
         Description=Setup Network Environment
         Documentation=http://github.com/kelseyhightower/setup-network-environment
         Requires=network-online.target cni-install.service
         After=network-online.target cni-install.service
         [Service]
         ExecStart=/opt/bin/setup-network-environment
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "kube-apiserver.service"
       enable: true
       contents: |
         [Unit]
         Description=Kubernetes API Server
         Documentation=https://github.com/kubernetes/kubernetes
         Requires=setup-network-environment.service etcd-member.service docker.service flanneld.service
         After=setup-network-environment.service etcd-member.service docker.service flanneld.service
         [Service]
         EnvironmentFile=/etc/network-environment
         ExecStart=/opt/bin/kube-apiserver \
           --anonymous-auth="false" \
           --enable-bootstrap-token-auth="true" \
           --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,DefaultStorageClass \
           --client-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --service-account-key-file="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --tls-private-key-file="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --tls-cert-file="/etc/kubernetes/ssl/etcd-node.pem" \
           --etcd-cafile="/etc/kubernetes/ssl/ca.pem" \
           --etcd-certfile="/etc/kubernetes/ssl/etcd-node.pem" \
           --etcd-keyfile="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --kubelet-certificate-authority="/etc/kubernetes/ssl/ca.pem" \
           --kubelet-client-certificate="/etc/kubernetes/ssl/etcd-node.pem" \
           --kubelet-client-key="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --proxy-client-cert-file="/etc/kubernetes/ssl/etcd-node.pem" \
           --proxy-client-key-file="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --requestheader-client-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --cert-dir="/etc/kubernetes/ssl" \
           --kubelet-https="true" \
           --service-cluster-ip-range=10.100.0.0/16 \
           --service-node-port-range=30000-32767 \
           --etcd-servers=https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379 \
           --advertise-address=10.9.56.102 \
           --allow-privileged="true" \
           --apiserver-count=3 \
           --audit-log-maxage=30 \
           --audit-log-maxbackup=3 \
           --audit-log-maxsize=100 \
           --audit-log-path="/var/log/audit.log" \
           --authorization-mode=Node,RBAC \
           --bind-address=0.0.0.0 \
           --storage-backend="etcd3" \
           --storage-media-type="application/vnd.kubernetes.protobuf" \
           --event-ttl=1h \
           --secure-port=6443 \
           --logtostderr="true" \
           --runtime-config=api/all=true \
           --v=3
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "kube-controller-manager.service"
       enable: true
       contents: |
         [Unit]
         Description=Kubernetes Controller Manager
         Documentation=https://github.com/kubernetes/kubernetes
         Requires=setup-network-environment.service
         After=setup-network-environment.service
         [Service]
         EnvironmentFile=/etc/network-environment
         ExecStart=/opt/bin/kube-controller-manager \
           --controllers=*,bootstrapsigner,tokencleaner \
           --allocate-node-cidrs="true" \
           --client-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --service-account-private-key-file="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --requestheader-client-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --root-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --tls-cert-file="/etc/kubernetes/ssl/ca.pem" \
           --tls-private-key-file="/etc/kubernetes/ssl/ca-key.pem" \
           --cluster-signing-cert-file="/etc/kubernetes/ssl/ca.pem" \
           --cluster-signing-key-file="/etc/kubernetes/ssl/ca-key.pem" \
           --cert-dir="/etc/kubernetes/ssl" \
           --authentication-kubeconfig="/etc/kubernetes/ssl/kubeconfig-kube-controller-manager.yaml" \
           --authorization-kubeconfig="/etc/kubernetes/ssl/kubeconfig-kube-controller-manager.yaml" \
           --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kube-controller-manager.yaml" \
           --bind-address=0.0.0.0 \
           --service-cluster-ip-range=10.100.0.0/16 \
           --master=https://10.9.56.102:6443 \
           --cluster-cidr=10.244.0.0/17 \
           --cluster-name="kubernetes-the-hard-way" \
           --use-service-account-credentials="true" \
           --leader-elect="true" \
           --logtostderr="true" \
           --v=3
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "kube-scheduler.service"
       enable: true
       contents: |
         [Unit]
         Description=Kubernetes Scheduler
         Documentation=https://github.com/kubernetes/kubernetes
         Requires=setup-network-environment.service
         After=setup-network-environment.service
         [Service]
         EnvironmentFile=/etc/network-environment
         ExecStart=/opt/bin/kube-scheduler \
           --client-ca-file="/etc/kubernetes/ssl/ca.pem" \
           --tls-cert-file="/etc/kubernetes/ssl/etcd-node.pem" \
           --tls-private-key-file="/etc/kubernetes/ssl/etcd-node-key.pem" \
           --cert-dir="/etc/kubernetes/ssl" \
           --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kube-scheduler.yaml" \
           --master=https://10.9.56.102:6443 \
           --config="/var/lib/kube-scheduler/kube-scheduler.yaml" \
           --write-config-to="/etc/kube-scheduler.service.conf" \
           --logtostderr=true \
           --v=3
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "kube-proxy.service"
       enable: true
       contents: |
         [Unit]
         Description=Kubernetes Proxy
         Documentation=https://github.com/kubernetes/kubernetes
         Requires=setup-network-environment.service
         After=setup-network-environment.service
         [Service]
         # wait for kubernetes master to be up and ready
         ExecStart=/opt/bin/kube-proxy \
           --config="/var/lib/kubeproxy/kube-proxy-config.yaml" \
           --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kube-proxy-master.yaml" \
           --hostname-override=manager-02.mncplaymedia.com \
           --bind-address=0.0.0.0 \
           --cluster-cidr=10.244.0.0/17 \
           --master=https://10.9.56.102:6443 \
           --proxy-mode="ipvs" \
           --masquerade-all \
           --logtostderr="true" \
           --v=3
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "kube-kubelet.service"
       enable: true
       contents: |
         [Unit]
         Description=Kubernetes Kubelet
         Documentation=https://github.com/kubernetes/kubernetes
         Requires=setup-network-environment.service
         After=setup-network-environment.service
         [Service]
         Environment=no_proxy=localhost,127.0.0.0/8,127.0.0.1,::1,10.9.56.101,10.9.56.102,10.9.56.103,manager-01,manager-02,manager-03,manager-01.mncplaymedia.com,manager-02.mncplaymedia.com,manager-03.mncplaymedia.com,mncplaymedia.com,/var/run/docker.sock
         EnvironmentFile=/etc/network-environment
         # wait for kubernetes master to be up and ready
         ExecStart=/opt/bin/kubelet \
           --bootstrap-kubeconfig="/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml" \
           --hostname-override=manager-02.mncplaymedia.com \
           --kubeconfig="/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml" \
           --config="/var/lib/kubelet/kubelet-config.yaml" \
           --cert-dir="/etc/kubernetes/ssl" \
           --volume-plugin-dir="/etc/kubernetes/kubelet-plugins/volume/exec" \
           --image-pull-progress-deadline=2m \
           --lock-file="/var/run/lock/kubelet.lock" \
           --exit-on-lock-contention \
           --logtostderr="true" \
           --register-node="true" \
           --node-labels="label=master" \
           --v=3
         Restart=on-failure
         RestartSec=5
         [Install]
         WantedBy=multi-user.target
     - name: "portainer.service"
       enable: true
       contents: |
         [Unit]
         Description=portainer
         Requires=docker.service
         After=docker.service
         [Service]
         Restart=always
         ExecStartPre=-/usr/bin/docker rm portainer
         ExecStart=/usr/bin/docker run --net=host --privileged \
           -v /var/run/docker.sock:/var/run/docker.sock \
           -v /etc/portainer/data:/data \
           --name portainer portainer/portainer
         ExecStop=-/usr/bin/docker stop portainer
         ExecStopPost=-/usr/bin/docker rm portainer
         [Install]
         WantedBy=multi-user.target
     - name: "vmware-octant.service"
       enable: true
       contents: |
         [Unit]
         Description=vmware octant
         [Service]
         ExecStart=sudo /opt/bin/octant
         Restart=on-failure
         RestartSec=10
         [Install]
         WantedBy=multi-user.target
     - name: "cni-install.service"
       enable: true
       contents: |
         [Unit]
         Description=Installs cni tools
         [Service]
         ExecStart=/opt/bin/cni-install.sh
         RemainAfterExit=yes
         Type=oneshot
     - name: "ETCDCTL_APIv2.service"
       enable: true
       contents: |
         [Unit]
         Description=Installs flannel key
         [Service]
         ExecStart=/opt/bin/ETCDCTL_APIv2.sh
         RemainAfterExit=yes
         Type=oneshot
update:
    group: "stable"
    server: "https://public.update.core-os.net/v1/update/"
networkd:
  units:
     - name: "00-eth0.network"
       contents: |
         [Match]
         Name=ens32
         [Network]
         DNS=10.100.0.10
         DNS=10.9.35.29
         DNS=10.9.35.30
         Domains=default.svc.cluster.local
         Domains=svc.cluster.local
         Domains=cluster.local
         Domains=mncplaymedia.com
         Address=10.9.56.102/24
         Gateway=10.9.56.1
     - name: "00-eth1.network"
       contents: |
         [Match]
         Name=ens33
         [Network]
         Address=192.168.56.2/24    
storage:
  disks:
    - device: "/dev/sdb"
  files:
    - filesystem: "root"
      path: "/etc/motd"
      mode: 0644
      contents:
        inline: |       
          ==============================================
          --- Kubernetes Master-02                   ---
          --- inet & etcd ip:     10.9.56.102        ---
          --- private ip:         192.168.56.2       ---
          ==============================================
    
    - filesystem: "root"
      path: "/etc/nsswitch.conf"
      mode: 0644
      contents:
        inline: |
          # /etc/nsswitch.conf:

          passwd:      files usrfiles
          shadow:      files usrfiles
          group:       files usrfiles

          hosts:       files usrfiles resolve dns
          networks:    files usrfiles dns

          services:    files usrfiles
          protocols:   files usrfiles
          rpc:         files usrfiles

          ethers:      files
          netmasks:    files
          netgroup:    files
          bootparams:  files
          automount:   files
          aliases:     files
    
    - filesystem: "root"
      path: "/etc/dnsmasq/dnsmasq.conf"
      mode: 0644
      contents:
        inline: |
          domain-needed
          bogus-priv
          no-hosts
          keep-in-foreground
          no-resolv
          expand-hosts
          server=10.100.0.10
          server=10.9.35.29
          server=10.9.35.30
          server=/svc.cluster.local/10.100.0.10
          
    - filesystem: "root"
      path: "/etc/conf.d/nfs"
      mode: 0644
      contents:
        inline: |
          OPTS_RPC_MOUNTD=""
    
    - filesystem: "root"
      path: "/var/log/audit.log"
      mode: 0644
    
    - filesystem: "root"
      path: "/var/log/container.log"
      mode: 0644
      
    - filesystem: "root"
      path: "/opt/bin/add-iptables.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo iptables -t nat -A PREROUTING -d 10.9.56.102 -p tcp --dport 8080 -j DNAT --to-destination 127.0.0.1
          sudo iptables -P FORWARD ACCEPT
          
    - path: /etc/kubernetes/ssl/01.secret-bootstrap-token.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Secret
          metadata:
            name: bootstrap-token-a8d019
            namespace: kube-system
          
          # Name MUST be of form "bootstrap-token-<token id>"
          # Type MUST be 'bootstrap.kubernetes.io/token'
          # $ echo $(openssl rand -hex 3).$(openssl rand -hex 8)
          type: bootstrap.kubernetes.io/token
          stringData:
            # Human readable description. Optional.
            description: "Created for Kubernetes the Hard Way"
          
            # Token ID and secret. Required.
            # $ echo $(openssl rand -hex 3).$(openssl rand -hex 8)
            token-id: a8d019
            token-secret: b1df9106fa0dee9f
          
            # Allowed usages.
            usage-bootstrap-authentication: "true"
            usage-bootstrap-signing: "true"
    
    - path: /etc/kubernetes/ssl/kubeconfig-kube-controller-manager.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          preferences: {}
          clusters:
          - name: kubernetes-the-hard-way
            cluster:
              server: https://10.9.56.102:6443
              certificate-authority: /etc/kubernetes/ssl/ca.pem
          users:
          - name: kube-controller-manager
            user:
              client-certificate: /etc/kubernetes/ssl/kube-controller-manager.pem
              client-key: /etc/kubernetes/ssl/kube-controller-manager-key.pem
          contexts:
          - context:
              cluster: kubernetes-the-hard-way
              user: kube-controller-manager
            name: kubernetes-the-hard-way
          current-context: kubernetes-the-hard-way
    
    - path: /etc/kubernetes/ssl/kubeconfig-kube-scheduler.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          preferences: {}
          clusters:
          - name: kubernetes-the-hard-way
            cluster:
              server: https://10.9.56.102:6443
              certificate-authority: /etc/kubernetes/ssl/ca.pem
          users:
          - name: kube-scheduler
            user:
              client-certificate: /etc/kubernetes/ssl/kube-scheduler.pem
              client-key: /etc/kubernetes/ssl/kube-scheduler-key.pem
          contexts:
          - context:
              cluster: kubernetes-the-hard-way
              user: kube-scheduler
            name: kubernetes-the-hard-way
          current-context: kubernetes-the-hard-way
              
    - path: /etc/kubernetes/ssl/kubeconfig-kube-proxy-master.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          preferences: {}
          clusters:
          - name: kubernetes-the-hard-way
            cluster:
              server: https://10.9.56.102:6443
              certificate-authority: /etc/kubernetes/ssl/ca.pem
          users:
          - name: kube-proxy
            user:
              client-certificate: /etc/kubernetes/ssl/kube-proxy-master.pem
              client-key: /etc/kubernetes/ssl/kube-proxy-master-key.pem
          contexts:
          - context:
              cluster: kubernetes-the-hard-way
              user: kube-proxy
            name: kubernetes-the-hard-way
          current-context: kubernetes-the-hard-way
            
    # kube-scheduler file.
    - filesystem: "root"
      path: "/var/lib/kube-scheduler/kube-scheduler.yaml"
      mode: 0644
      contents:
        inline: |
          apiVersion: kubescheduler.config.k8s.io/v1alpha1
          kind: KubeSchedulerConfiguration
          algorithmSource:
            provider: DefaultProvider
          disablePreemption: true
          clientConnection:
            kubeconfig: "/etc/kubernetes/ssl/kubeconfig-kube-scheduler.yaml"
          leaderElection:
            leaderElect: true
              
    - filesystem: "root"
      path: "/etc/hostname"
      mode: 0644
      contents:
        inline: manager-02.mncplaymedia.com
          
    - filesystem: "root"
      path: "/opt/bin/cni-install.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          if [ ! -f /opt/bin/setup-network-environment ]; then
            sudo mkdir -p /etc/kubernetes/kubelet-plugins/volume/exec/
            sudo mkdir -p /var/etcd/data/
            sudo mkdir -p /etc/bird/
            sudo mkdir -p /etc/ceph/
            sudo mkdir -p /etc/docker/
            sudo mkdir -p /home/core/.kube/
            sudo chown -R core:core /home/core/.kube/
            sudo mkdir -p /home/admin/.kube/
            sudo chown -R admin:admin /home/admin/.kube/
            sudo mkdir -p /etc/kube-flannel/
            sudo mkdir -p /etc/sysconfig/
            sudo mkdir -p /etc/portainer/data/
            sudo mkdir -p /coreos.com/network/
            sudo mkdir -p /var/lib/etcd/ssl/
            sudo mkdir -p /var/lib/kubeproxy/
            sudo mkdir -p /var/lib/kubelet/
            sudo mkdir -p /var/lib/kube-scheduler/
            sudo mkdir -p /var/lib/kube-controller-manager/
            sudo mkdir -p /etc/ssl/certs/
            sudo mkdir -p /etc/ssl/etcd/
            sudo mkdir -p /etc/dnsmasq/
            sudo mkdir -p /run/dbus/
            sudo mkdir -p /opt/bin/
            sudo mkdir -p /etc/coredns/tls/etcd/
            sudo mkdir -p /opt/bin/scripts/
            sudo mkdir -p /etc/kubernetes/cni/net.d/
            sudo mkdir -p /etc/rkt/net.d/
            sudo mkdir -p /etc/cni/net.d/
            sudo mkdir -p /opt/plugins/
            sudo mkdir -p /opt/cni/bin/
            sudo mkdir -p /opt/cni/backup/
            sudo mkdir -p /etc/kubernetes/manifests/
            sudo mkdir -p /etc/kubernetes/ssl/
            sudo mkdir -p /etc/kubernetes/pki/
            sudo mkdir -p /etc/kubernetes/addons/
            sudo mkdir -p /opt/plugins/usr/local/sbin/
            sudo mkdir -p /opt/plugins/usr/local/bin/
            sudo mkdir -p /opt/plugins/etc/systemd/system/
            sudo mkdir -p /opt/prometheus/{conf,data}
            sudo chown 65534:65534 /opt/prometheus/data
            sudo mkdir -p /data/grafana/data/
            sudo mkdir -p /data/logstash/data/
            sudo mkdir -p /data/elasticsearch/data/
            sudo chown -R 1000.1000 /data
            echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf && sudo sysctl -p
            echo "CNI not installed - installing."
            export K8S_VERSION=v1.15.9
            sudo wget -q -N -P /opt/bin --show-progress --https-only --timestamping \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kubectl \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kube-apiserver \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kube-controller-manager \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kube-scheduler \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kube-proxy \
                 https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kubelet \
                 https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64 \
                 https://github.com/kubernetes/kubernetes/releases/download/${K8S_VERSION}/kubernetes.tar.gz \
                 https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.17.0/crictl-v1.17.0-linux-amd64.tar.gz \
                 https://github.com/johanhaleby/kubetail/archive/1.6.10.tar.gz \
                 https://azuredraft.blob.core.windows.net/draft/draft-v0.16.0-linux-amd64.tar.gz \
                 https://kubernetes-helm.storage.googleapis.com/helm-v2.16.1-linux-amd64.tar.gz \
                 https://github.com/vmware-tanzu/octant/releases/download/v0.10.0/octant_0.10.0_Linux-64bit.tar.gz
            sudo chmod +x /opt/bin/kubectl /opt/bin/kube-apiserver /opt/bin/kube-controller-manager /opt/bin/kube-scheduler /opt/bin/kube-proxy /opt/bin/kubelet
            sudo wget -q -N -P /opt/bin --show-progress --timestamping \
                 http://github.com/kelseyhightower/setup-network-environment/releases/download/1.0.1/setup-network-environment
            sudo chmod +x /opt/bin/setup-network-environment
            sudo wget -q -N -P /opt/plugins --show-progress --https-only --timestamping \
                 https://github.com/containernetworking/plugins/releases/download/v0.8.5/cni-plugins-linux-amd64-v0.8.5.tgz \
                 https://github.com/containernetworking/cni/releases/download/v0.6.0/cni-amd64-v0.6.0.tgz
            sudo tar -xvf /opt/plugins/cni-plugins-linux-amd64-v0.8.5.tgz -C /opt/cni/bin/
            sudo tar -xvf /opt/plugins/cni-amd64-v0.6.0.tgz -C /opt/cni/bin/
            sudo tar -xvf /opt/bin/crictl-v1.17.0-linux-amd64.tar.gz -C /opt/bin/
            sudo tar -xvf /opt/bin/1.6.10.tar.gz -C /opt/bin/
            sudo tar -xvf /opt/bin/helm-v2.16.1-linux-amd64.tar.gz -C /opt/bin/
            sudo tar -xvf /opt/bin/octant_0.10.0_Linux-64bit.tar.gz -C /opt/bin/
            sudo mv /opt/bin/linux-amd64/helm /opt/bin/helm
            sudo mv /opt/bin/linux-amd64/tiller /opt/bin/tiller
            sudo mv /opt/bin/octant_0.10.0_Linux-64bit/octant /opt/bin/octant
            sudo chmod +x /opt/bin/octant
            sudo tar -xvf /opt/bin/draft-v0.16.0-linux-amd64.tar.gz -C /opt/bin/
            sudo mv /opt/bin/linux-amd64/draft /opt/bin/draft
            sudo mv /opt/bin/kubetail-1.6.10/kubetail /opt/bin/kubetail
            sudo mv /opt/bin/jq-linux64 /opt/bin/jq
            sudo chmod +x /opt/bin/jq
            sudo tar -xvf /opt/bin/kubernetes.tar.gz -C /opt/bin/
            sudo tar -xvf /opt/bin/kubernetes/server/kubernetes-manifests.tar.gz -C /opt/bin/kubernetes/server/
            sudo git clone https://github.com/ahmetb/kubectx.git /opt/bin/kubectx-folder
            sudo cp /opt/bin/kubectx-folder/kubens /opt/bin/kubens
            sudo cp /opt/bin/kubectx-folder/kubectx /opt/bin/kubectx
            sudo systemctl start user@0.service
            sudo systemctl start locksmith-profile.service
            sudo systemctl start rpc-statd.service
            sudo systemctl start clean-dangling.service
            sudo systemctl stop etcd-member.service
            sudo /opt/bin/add-iptables.sh
            sudo sysctl -w vm.max_map_count=262144
            sudo cp -R /opt/cni/bin/* /opt/cni/backup/
            sudo systemctl start ETCDCTL_APIv2.service
          else
            sudo systemctl start user@0.service
            sudo systemctl start etcd-v3-datastore.service
            sudo systemctl start locksmith-profile.service
            sudo systemctl start rpc-statd.service
            sudo systemctl start clean-dangling.service
            sudo systemctl stop etcd-member.service
            sudo /opt/bin/add-iptables.sh
            sudo sysctl -w vm.max_map_count=262144
            sudo cp -R /opt/cni/bin/* /opt/cni/backup/
            sudo systemctl start ETCDCTL_APIv2.service
          fi
    
    # kubelet-config file.
    - filesystem: "root"
      path: "/var/lib/kubelet/kubelet-config.yaml"
      mode: 0644
      contents:
        inline: |
          address: 0.0.0.0
          apiVersion: kubelet.config.k8s.io/v1beta1
          authentication:
            anonymous:
              enabled: false
            webhook:
              cacheTTL: 2m0s
              enabled: true
            x509:
              clientCAFile: "/etc/kubernetes/ssl/ca.pem"
          authorization:
            mode: Webhook
            webhook:
              cacheAuthorizedTTL: 5m0s
              cacheUnauthorizedTTL: 30s
          cgroupDriver: cgroupfs
          cgroupsPerQOS: true
          clusterDomain: "cluster.local"
          clusterDNS: 
            - "10.100.0.10"
          containerLogMaxFiles: 5
          containerLogMaxSize: 10Mi
          contentType: application/vnd.kubernetes.protobuf
          cpuCFSQuota: true
          cpuManagerPolicy: none
          cpuManagerReconcilePeriod: 10s
          enableControllerAttachDetach: true
          enableDebuggingHandlers: true
          enforceNodeAllocatable:
            - pods
          eventBurst: 10
          eventRecordQPS: 5
          evictionHard:
            imagefs.available: 15%
            memory.available: 100Mi
            nodefs.available: 10%
            nodefs.inodesFree: 5%
          evictionPressureTransitionPeriod: 5m0s
          failSwapOn: true
          fileCheckFrequency: 20s
          hairpinMode: promiscuous-bridge
          healthzBindAddress: 127.0.0.1
          healthzPort: 10248
          httpCheckFrequency: 20s
          imageGCHighThresholdPercent: 85
          imageGCLowThresholdPercent: 80
          imageMinimumGCAge: 2m0s
          iptablesDropBit: 15
          iptablesMasqueradeBit: 14
          kind: KubeletConfiguration
          tlsCertFile: "/etc/kubernetes/ssl/etcd-node.pem"
          tlsPrivateKeyFile: "/etc/kubernetes/ssl/etcd-node-key.pem"
          RotateCertificates: true
          ServerTLSBootstrap: true
          kubeAPIBurst: 10
          kubeAPIQPS: 5
          makeIPTablesUtilChains: true
          maxOpenFiles: 1000000
          maxPods: 110
          nodeStatusUpdateFrequency: 10s
          oomScoreAdj: -999
          podPidsLimit: -1
          port: 10250
          registryBurst: 10
          registryPullQPS: 5
          runtimeRequestTimeout: 2m0s
          serializeImagePulls: true
          staticPodPath: /etc/kubernetes/manifests
          streamingConnectionIdleTimeout: 4h0m0s
          syncFrequency: 1m0s
          volumeStatsAggPeriod: 1m0s
          podCIDR: "10.9.56.0/24"
          resolvConf: "/run/systemd/resolve/resolv.conf"
          
    - filesystem: "root"
      path: "/opt/bin/ETCDCTL_APIv2.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo ETCDCTL_API=2 /usr/bin/etcdctl --ca-file=/etc/ssl/certs/ca.pem --cert-file=/var/lib/etcd/ssl/etcd-node.pem --key-file=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379" set /coreos.com/network/config '{ "Network":"10.244.0.0/16", "SubnetLen": 24, "SubnetMin": "10.244.0.0", "SubnetMax":"10.244.255.0", "Backend": {"Type": "vxlan"} }'
    
    - filesystem: "root"
      path: "/opt/bin/scripts/01.scripts-secret-bootstrap-token.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl create -f /etc/kubernetes/ssl/01.secret-bootstrap-token.yaml --validate=false
          
    - filesystem: "root"
      path: "/opt/bin/scripts/kubectl-config.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo /opt/bin/scripts/002.scripts-kubelet.sh
    
    - filesystem: "root"
      path: "/opt/bin/scripts/refresh-octant.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo /opt/bin/scripts/008.restart-octant.sh
    
    - filesystem: "root"
      path: "/opt/bin/scripts/008.restart-octant.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo systemctl stop vmware-octant.service
          sudo systemctl start vmware-octant.service
          
    - filesystem: "root"
      path: "/opt/bin/scripts/001.scripts-bootstrap-token.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo /opt/bin/scripts/01.scripts-secret-bootstrap-token.sh
          sudo /opt/bin/scripts/02.scripts-RBAC-policies-to-enable-bootstrapping.sh
          
    - filesystem: "root"
      path: "/opt/bin/scripts/002.scripts-kubelet.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo /opt/bin/scripts/03.scripts-kubectl-kubelet-bootstrap.sh
    
    - filesystem: "root"
      path: "/opt/bin/scripts/003.scripts-others.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo /opt/bin/scripts/04.scripts-flannel-rbac.sh
          sudo /opt/bin/scripts/05.scripts-kube-apiserver-to-kubelet-and-helm.sh
    
    - filesystem: "root"
      path: "/opt/bin/scripts/004.scripts-helm-others.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo helm init --service-account tiller
          sudo helm init --client-only
          sudo helm repo update
    
    - filesystem: "root"
      path: "/opt/bin/scripts/005.copy-token-config.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl config view --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml --raw > /root/.kube/config
          sudo kubectl config view --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml --raw > /home/core/.kube/config
          sudo kubectl config view --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml --raw > /home/admin/.kube/config
    
    - filesystem: "root"
      path: "/opt/bin/scripts/006.grant-permission-apiserver-to-kubelet-client-user.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl create clusterrolebinding apiserver-kubelet-api-admin --clusterrole system:kubelet-api-admin --user kubernetes
          sudo kubectl create clusterrolebinding \
            --clusterrole=cluster-admin\
            --user=system:bootstrap:a8d019 \
            --clusterrole=cluster-admin \
            --user=system:serviceaccount \
            grant-permission-kubelet-admin-binding
          sudo kubectl create clusterrolebinding \
            --clusterrole=cluster-admin\
            --user=system:node:manager-01.mncplaymedia.com \
            --clusterrole=cluster-admin \
            --user=system:serviceaccount \
            grant-permission-manager-01-admin-binding
          sudo kubectl create clusterrolebinding \
            --clusterrole=cluster-admin\
            --user=system:node:manager-02.mncplaymedia.com \
            --clusterrole=cluster-admin \
            --user=system:serviceaccount \
            grant-permission-manager-02-admin-binding
          sudo kubectl create clusterrolebinding \
            --clusterrole=cluster-admin\
            --user=system:node:manager-03.mncplaymedia.com \
            --clusterrole=cluster-admin \
            --user=system:serviceaccount \
            grant-permission-manager-03-admin-binding
                
    - filesystem: "root"
      path: "/opt/bin/scripts/02.scripts-RBAC-policies-to-enable-bootstrapping.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl create clusterrolebinding kubelet-bootstrap \
            --clusterrole=system:node-bootstrapper \
            --group=system:bootstrappers
          
          sudo kubectl create clusterrolebinding node-autoapprove-bootstrap \
            --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \
            --group=system:bootstrappers
          
          sudo kubectl create clusterrolebinding node-autoapprove-certificate-rotation \
            --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \
            --group=system:nodes
    
    - filesystem: "root"
      path: "/opt/bin/scripts/03.scripts-kubectl-kubelet-bootstrap.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl config set-cluster kubernetes-the-hard-way \
            --certificate-authority=/etc/kubernetes/ssl/ca.pem \
            --embed-certs=true \
            --server=https://10.9.56.101:6443 \
            --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          
          sudo kubectl config set-credentials kubelet-bootstrap \
            --token=a8d019.b1df9106fa0dee9f \
            --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          
          sudo kubectl config set-context kubernetes-the-hard-way \
            --cluster=kubernetes-the-hard-way \
            --user=kubelet-bootstrap \
            --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          
          sudo kubectl config use-context kubernetes-the-hard-way \
            --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
    
    - filesystem: "root"
      path: "/opt/bin/scripts/04.scripts-flannel-rbac.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl apply --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kubelet-master.yaml" -f /opt/bin/scripts/kube-flannel.yaml
          
    - filesystem: "root"
      path: "/opt/bin/scripts/05.scripts-kube-apiserver-to-kubelet-and-helm.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          sudo kubectl apply --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kubelet-master.yaml" -f /opt/bin/scripts/ClusterRole.yaml
          sudo kubectl apply --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kubelet-master.yaml" -f /opt/bin/scripts/kube-apiserver-to-kubelet.yaml
          sudo kubectl apply --kubeconfig="/etc/kubernetes/ssl/kubeconfig-kubelet-master.yaml" -f /opt/bin/scripts/ServiceAccount-for-helm-RBAC.yaml
    
    - filesystem: "root"
      path: "/opt/bin/scripts/ServiceAccount-for-helm-RBAC.yaml"
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: tiller
            namespace: kube-system
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: tiller
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: cluster-admin
          subjects:
            - kind: ServiceAccount
              name: tiller
              namespace: kube-system
              
    - filesystem: "root"
      path: "/opt/bin/scripts/ClusterRole.yaml"
      mode: 0644
      contents:
        inline: |
          apiVersion: rbac.authorization.k8s.io/v1beta1
          kind: ClusterRole
          metadata:
            annotations:
              rbac.authorization.kubernetes.io/autoupdate: "true"
            labels:
              kubernetes.io/bootstrapping: rbac-defaults
            name: system:kube-apiserver-to-kubelet
          rules:
            - apiGroups:
                - ""
              resources:
                - nodes/proxy
                - nodes/stats
                - nodes/log
                - nodes/spec
                - nodes/metrics
              verbs:
                - "*"
    
    - filesystem: "root"
      path: "/opt/bin/scripts/kube-apiserver-to-kubelet.yaml"
      mode: 0644
      contents:
        inline: |
          apiVersion: rbac.authorization.k8s.io/v1beta1
          kind: ClusterRoleBinding
          metadata:
            name: system:kube-apiserver
            namespace: ""
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: system:kube-apiserver-to-kubelet
          subjects:
            - apiGroup: rbac.authorization.k8s.io
              kind: User
              name: kubernetes
    
    - path: /etc/kubernetes/ssl/kubeconfig-kubelet-master.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          clusters:
          - name: local
            cluster:
              certificate-authority: /etc/kubernetes/ssl/ca.pem
              server: https://10.9.56.102:6443
          contexts:
          - context:
              cluster: kubernetes-the-hard-way
              user: kubelet-bootstrap
            name: kubernetes-the-hard-way
          current-context: kubernetes-the-hard-way
          preferences: {}
          users:
          - name: kubelet-bootstrap
            user:
              token: a8d019.b1df9106fa0dee9f
          
    - filesystem: "root"
      path: "/opt/bin/scripts/kube-flannel.yaml"
      mode: 0644
      contents:
        inline: |
          ---
        
          kind: ClusterRole
          apiVersion: rbac.authorization.k8s.io/v1beta1
          metadata:
            name: flannel
          rules:
            - apiGroups: ['extensions']
              resources: ['podsecuritypolicies']
              verbs: ['use']
              resourceNames: ['psp.flannel.unprivileged']
            - apiGroups:
                - ""
              resources:
                - pods
              verbs:
                - get
            - apiGroups:
                - ""
              resources:
                - nodes
              verbs:
                - list
                - watch
            - apiGroups:
                - ""
              resources:
                - nodes/status
              verbs:
                - patch
          ---
          kind: ClusterRoleBinding
          apiVersion: rbac.authorization.k8s.io/v1beta1
          metadata:
            name: flannel
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: flannel
          subjects:
          - kind: ServiceAccount
            name: flannel
            namespace: kube-system
          ---
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: flannel
            namespace: kube-system
          ---
          kind: ConfigMap
          apiVersion: v1
          metadata:
            name: kube-flannel-cfg
            namespace: kube-system
            labels:
              tier: node
              app: flannel
          data:
            cni-conf.json: |
              {
                "name": "cni0",
                "plugins": [
                  {
                    "type": "flannel",
                    "delegate": {
                      "hairpinMode": true,
                      "isDefaultGateway": true
                    }
                  },
                  {
                    "type": "portmap",
                    "capabilities": {
                      "portMappings": true
                    }
                  }
                ]
              }
            net-conf.json: |
              {
                "Network": "10.244.0.0/16",
                "Backend": {
                  "Type": "vxlan"
                }
              }
              
    - filesystem: "root"
      path: "/etc/flannel/options.env"
      mode: 0644
      contents:
        inline: |
          ETCDCTL_CA_FILE=/etc/ssl/certs/ca.pem
          ETCDCTL_CERT_FILE=/var/lib/etcd/ssl/etcd-node.pem
          ETCDCTL_KEY_FILE=/var/lib/etcd/ssl/etcd-node-key.pem
          ETCDCTL_ENDPOINTS="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
          FLANNELD_IFACE="ens32"
          FLANNELD_ETCD_ENDPOINTS="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
          FLANNELD_ETCD_PREFIX="/coreos.com/network"
          no_proxy=localhost,127.0.0.0/8,127.0.0.1,::1,10.9.56.101,10.9.56.102,10.9.56.103,manager-01,manager-02,manager-03,manager-01.mncplaymedia.com,manager-02.mncplaymedia.com,manager-03.mncplaymedia.com,mncplaymedia.com,/var/run/docker.sock
          
    - filesystem: "root"
      path: "/run/systemd/system/etcd.service.d/30-certificates.conf"
      mode: 0644
      contents:
        inline: |
          [Service]
          # Client Env Vars
          Environment=ETCD_TRUSTED_CA_FILE=/etc/ssl/certs/ca.pem
          Environment=ETCD_CA_FILE=/etc/ssl/certs/ca.pem
          Environment=ETCD_CERT_FILE=/var/lib/etcd/ssl/etcd-node.pem
          Environment=ETCD_KEY_FILE=/var/lib/etcd/ssl/etcd-node-key.pem
          Environment=ETCD_DATA_DIR=/var/lib/etcd
          # Peer Env Vars
          Environment=ETCD_PEER_TRUSTED_CA_FILE=/etc/ssl/certs/ca.pem
          Environment=ETCD_PEER_CA_FILE=/etc/ssl/certs/ca.pem
          Environment=ETCD_PEER_CERT_FILE=/var/lib/etcd/ssl/etcd-node.pem
          Environment=ETCD_PEER_KEY_FILE=/var/lib/etcd/ssl/etcd-node-key.pem
    
    - filesystem: "root"
      path: "/etc/hosts"
      mode: 0644
      contents:
        inline: |
          # /etc/hosts: Local Host Database
          #
          # This file describes a number of aliases-to-address mappings for the for 
          # local hosts that share this file.
          #
          # The format of lines in this file is:
          #
          # IP_ADDRESS    canonical_hostname      [aliases...]
          #
          #The fields can be separated by any number of spaces or tabs.
          #
          # In the presence of the domain name service or NIS, this file may not be 
          # consulted at all; see /etc/host.conf for the resolution order.
          #
          
          # IPv4 and IPv6 localhost aliases
          127.0.0.1         localhost
          ::1               localhost
          10.9.56.101       manager-01.mncplaymedia.com
          10.9.56.102       manager-02.mncplaymedia.com
          10.9.56.103       manager-03.mncplaymedia.com
          10.9.56.104       worker-001.mncplaymedia.com
          10.9.56.105       worker-002.mncplaymedia.com
          10.9.56.106       worker-003.mncplaymedia.com
          10.9.56.107       worker-004.mncplaymedia.com
          10.9.56.108       worker-005.mncplaymedia.com
          10.9.56.109       worker-006.mncplaymedia.com
          10.9.56.110       worker-007.mncplaymedia.com
          10.9.56.111       worker-008.mncplaymedia.com
          10.9.56.112       worker-009.mncplaymedia.com
          10.9.56.113       worker-010.mncplaymedia.com
          10.9.56.114       worker-011.mncplaymedia.com
          10.9.56.115       worker-012.mncplaymedia.com
          10.9.56.116       worker-013.mncplaymedia.com
          10.9.56.117       worker-014.mncplaymedia.com
          10.9.56.118       worker-015.mncplaymedia.com
          10.9.56.119       worker-016.mncplaymedia.com
          10.9.56.120       worker-017.mncplaymedia.com
          10.9.56.121       worker-018.mncplaymedia.com
          10.9.56.122       worker-019.mncplaymedia.com
          10.9.56.123       worker-020.mncplaymedia.com
          
          #
          # Imaginary network.
          #10.0.0.2               myname
          #10.0.0.3               myfriend
          #
          # According to RFC 1918, you can use the following IP networks for private 
          # nets which will never be connected to the Internet:
          #
          #       10.0.0.0        -   10.255.255.255
          #       172.16.0.0      -   172.31.255.255
          #       192.168.0.0     -   192.168.255.255
          #
          # In case you want to be able to connect directly to the Internet (i.e. not 
          # behind a NAT, ADSL router, etc...), you need real official assigned 
          # numbers.  Do not try to invent your own network numbers but instead get one 
          # from your network provider (if any) or from your regional registry (ARIN, 
          # APNIC, LACNIC, RIPE NCC, or AfriNIC.)
          #
    
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/ca-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEogIBAAKCAQEAtLFdH094CypU7j6r8ToKJ+KsLnDw1RNNHb/Qp2+wWailXQ8H
          aby4QcJKbt1zAwJceNvP6iMFPypp8FB0tIZOIcvoq16QkztOnlrg7CMvdutdhlze
          hefxXFrHaNnekOA/Ss8uvyH7Z5bj7+BmmrtAo0jzzh12RS+qIwnBYLgSr01jRKV3
          F868tPG273Yyb+HaCQTQWXoGfVfiT1va6zB/IEXlWt/K0FmM7uMyVPlAlxq214NS
          daEz+e8qORuLp5EhZp58cwSotLxAcdYdRurIyPnGwZ4cjvTg97FH55fhQ+x7jkSX
          s09Hbq95yEtBJ9RWL83SHr2mckIQM+MSzJelqwIDAQABAoIBAG33p3HfvnIlIC0i
          jSgxJ28gv6M/7wHuTjd1vnm4On5GaeVZuSw7w3OZ2AzizxUcwcR4GnAnQhEwMesk
          O/KF7lUZMQ/ibGB+bplnO43a2A8qrO+R44dhIn4PbV69gXtwTnSr5IpEFynzJeOe
          ETPIFE2Ln31oZssyd/v8+uhu/kga7elYJdlkAUad9BEZvmLrB76uCZMvLgVo+lgj
          CelNtyDPvZo0VGNPFqZMKQMgNiYUtdetKIoWSyqdQxMUwoT66ifOXAlOl7hCFid8
          RKDQ0OD+E5ci7MKhnO1RxymTCh2OVwF/hoCpqnlFKJKc7ZeR9NjVnSs+XIG+o3N3
          O/Rx43ECgYEA4Q8EafbyDr3QDFPjlmmlKpSDP9z7MfPQeNOsLGZJ8XIUNXBtflBG
          WgdEX9b6vqqE4l7yG7YbAhmd2fjyp/ZXD04N9UCF/tsAeqVKgxH9HhUs/xxQObg6
          04Qpr8zd7mqk/n8kNubbYTX7AW/KUrMAKJy8V7LQZO4xgKf3AfUgzBkCgYEAzYjh
          6jirRBoQ0EifL79KjSggvy+AUWeJbdPkgVmsuhEshIVgIyEXd6Z8tmwknLM30cKI
          kr+o+YxpsVjGisKHODkuCbf4CUfyLD2B4/k29GTSNmn87kklaRGXpmirtujPGbPV
          WlI7QW2aDyYTugILSmUJ4PURA8UJqoKDw2LFeGMCgYA3QfOofMxj2DDrxfEcLiYy
          dTJgjMZUNnPaJsagRCElmgfiMw9/MwCC/EPKcEMyazWjSwKQ0T6CXn3GVfxmRvKL
          PHPq4oPD1kug0VKhKdqG91YL8Qy1j0lKQ6nkkx1ue1q1bcwbesUkcheF+8emVHLW
          hd0sfyfxkBYxa4wXO/NoiQKBgGqcV+KwJlYa1yHSqY+Qv9DcQbApqXuQIv7u7BYU
          N74D7n2G2Ukffxa3KvVMvujxJUEOkNzdwX4/0QsGq2WKZa1KK5Eq9eOKiBlehiOE
          P3chXNCQxXusQVVwpKLSpE8qD1Kbr008XjQf78tvysevC8A5DJi9RWgZKlxheos8
          joVVAoGAdstAt/eB7gICZjIw2K7JKCxzHt1m6RdbXE7DJpQVZMYFBu1xlR1ZqY2m
          jiIZz1TY6mCfsVYl4119suolsuMCsQcUDpPpahvGAQseOlit0c805ISERT0oqWni
          mgqgSPn1nneydyzoIuHLsaYEvFojuDoxeOGCdRi0v1h/C2wBy+I=
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/ca.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIEljCCA36gAwIBAgIUU+WUWXU2Eb2mgs7Rr1G0ffEA/IAwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTEw
          MFoXDTI0MDcwMTIzMTEwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtLFdH094CypU7j6r8ToK
          J+KsLnDw1RNNHb/Qp2+wWailXQ8Haby4QcJKbt1zAwJceNvP6iMFPypp8FB0tIZO
          Icvoq16QkztOnlrg7CMvdutdhlzehefxXFrHaNnekOA/Ss8uvyH7Z5bj7+BmmrtA
          o0jzzh12RS+qIwnBYLgSr01jRKV3F868tPG273Yyb+HaCQTQWXoGfVfiT1va6zB/
          IEXlWt/K0FmM7uMyVPlAlxq214NSdaEz+e8qORuLp5EhZp58cwSotLxAcdYdRurI
          yPnGwZ4cjvTg97FH55fhQ+x7jkSXs09Hbq95yEtBJ9RWL83SHr2mckIQM+MSzJel
          qwIDAQABo4IBDDCCAQgwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8C
          AQIwHQYDVR0OBBYEFL0E08PW2vwH1/DKI7dCyBC0oKzZMB8GA1UdIwQYMBaAFL0E
          08PW2vwH1/DKI7dCyBC0oKzZMIGhBgNVHREEgZkwgZaHBH8AAAGHBApkAAGHBAoJ
          OGWHBAoJOGaHBAoJOGeHBAoJOGiHBAoJOGmHBAoJOGqHBAoJOGuHBAoJOGyHBAoJ
          OG2HBAoJOG6HBAoJOG+HBAoJOHCHBAoJOHGHBAoJOHKHBAoJOHOHBAoJOHSHBAoJ
          OHWHBAoJOHaHBAoJOHeHBAoJOHiHBAoJOHmHBAoJOHqHBAoJOHswDQYJKoZIhvcN
          AQELBQADggEBADYGbExdzqhRXOdFSNswme8w61qiMfdEDYfiqk1VnEiU5A8jCeZe
          AeTt5LJHhxVh5uu6LiGzBQPbLahF9MrBw0dty4f85NugN2dca/gUxy70GjHeZatS
          WpTthLV9vQ0SU6tgzT4tItzInK0o7jev10IEcgqozoG2Tj3f0CwBnj72moz1681B
          zwfAn3RhmqiVU9uh1tyXFfqTcfVHq4f/Qj/+F5621VbNWFQwkypy27O4SyRYM0b9
          wWsxCXXfQPCTVcd69XRu4dKWhL7X9z+0CGkeEFwE515pYzcOB1dWnTDo+DW2g6av
          S8utxK8/C4qecEL3p4DLqHwMgpKl/89L0JI=
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/etcd-node-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEowIBAAKCAQEAwge2SUSbIB1jHYgHtrpNDaogTbqwjVLWgXJw6yUpzM9cRr7M
          PG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4heuxmKj4AHw/ndNXrb6xiYELuUwE8
          dcrLab2ImnY2YyDE3I30uaUWcgH683pm/GdmGHoLwroyTnoa0b246pAj6eQU4nqe
          H3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QTKtYyCn4uKjmdoN95g8el1rak5D17
          s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6Nx4U5zY8XUns/ArjR1bxrNK19ZFOq
          VFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+QQIDAQABAoIBAHFYJ/gtB6F/CUNb
          D4aC1jhBRZWilTg5R+1eePAkSYLHL1R0aMJ1FP3cGjlalAasBLMI6E+oIpP8Zi5e
          XjI2hYBVUGkkxtVeaQsrW9lkjiNFdgsvEa6NxL4EZiQ1IhhOMDHXCzrXYYE//uT0
          f+y6Sj3KLcyXEIQfeENF3RvJD/G0sOUV0v6xgtO+NN1n0Esw9ffPR7yQ0DdlpWLY
          nbZC2mv+8xjRWaZTFF0GiuBbFDtEBQfDB501bdlypaHcP3Z1hFvutLztnnr3LFpZ
          cJAWYEuN6RPAq6BoMY40sjybSFJcmfO/DC+vChskzMDZLip3lYaAS3n4g2BHJori
          rsLBn/ECgYEAxYj78IQsnpuvqrKVNCoeI0USD4e3g6AiAxrpcYTPIcE5ciwNE9xH
          lplwdyCC/7fLxjh7V/uwU+FhTvqlItGuFUk2moNptin2IfiJ4mXHfzaqDYh6o4Xc
          60exW5Il+8Lkwm08zoHTtX27Gqlp6ycrTIw96q6VnCMCy2aDebM0bGsCgYEA+3Up
          CEAZDSxviBm5bMYBDglmHuPOfeMEVV4NL13uhU6Wk68D+7v6yFvo0WTOcqtybIp7
          7nz2CjF8Fdusp7Sgy49Yrjd0m827tIcEYJR69g1gqlHMzM7CbEujPHsUFrZOEHl5
          /DjTATQuyeovZGYGc9WkJPr61Nw2ejgsn/zFawMCgYEAluICZv3ewyvyK3WLKDQ/
          nvskR36H+192e160D4S9XnAkPARP3Oq2N99uG2BXD5LJcNg1xse2MOwHkvc66fS1
          fwbUUYOtXHqCygH4+Fh74LzVec7UtlEKpSC25VYl8z8z0xrzhl1+Y7PtFflvsTHT
          Df5VUQwXtRK9ELZ2GKB8m48CgYBTSYQUun5RsbUjZDnZgF/bEVvkwVmksqu9xtAh
          L0CQoO4Y7nAoUiQHdwHPUU9cBdN5hgj0filUSP2rk75FMfvMUKdz1ORnsqYIbmwR
          vTxZASdSYpOuBpG5IvhnUPDfcPS8WjAATaX+ERWqRUn7PBvJBCtBIGwyUtoscyy8
          tRGClwKBgGmDGa/fWyI1yS6zp8/pYt7dxQmljCwNPdDecgA3OzqgscGNys+9EQAW
          2oALKiGw0p0zuxx49Wd/9JoBqk+u8Vg2ab9ILnTjjHvYbo3rfDUjTMLERs5/Tmt/
          wQCe4OxmPIOftKJ8kJQuHPI+Mi7cQrhKUGO2RuE21BlSRBnkebjp
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/etcd-node.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIH6DCCBtCgAwIBAgIULy3KnguWZtIbB2ugQjgRjyct9YIwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTYw
          MFoXDTI5MDYzMDIzMTYwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwge2SUSbIB1jHYgHtrpN
          DaogTbqwjVLWgXJw6yUpzM9cRr7MPG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4h
          euxmKj4AHw/ndNXrb6xiYELuUwE8dcrLab2ImnY2YyDE3I30uaUWcgH683pm/Gdm
          GHoLwroyTnoa0b246pAj6eQU4nqeH3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QT
          KtYyCn4uKjmdoN95g8el1rak5D17s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6N
          x4U5zY8XUns/ArjR1bxrNK19ZFOqVFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+
          QQIDAQABo4IEXjCCBFowDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUF
          BwMBBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBSQ7QvsgkCU8RgZ
          7rHzBOePjpg0OTAfBgNVHSMEGDAWgBS9BNPD1tr8B9fwyiO3QsgQtKCs2TCCA9kG
          A1UdEQSCA9AwggPMggprdWJlcm5ldGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1
          YmVybmV0ZXMuZGVmYXVsdC5zdmOCHmt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1
          c3RlcoIka3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsghtrdWJl
          cm5ldGVzLm1uY3BsYXltZWRpYS5jb22CG21hbmFnZXItMDEubW5jcGxheW1lZGlh
          LmNvbYIbbWFuYWdlci0wMi5tbmNwbGF5bWVkaWEuY29tghttYW5hZ2VyLTAzLm1u
          Y3BsYXltZWRpYS5jb22CG3dvcmtlci0wMDEubW5jcGxheW1lZGlhLmNvbYIbd29y
          a2VyLTAwMi5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDAzLm1uY3BsYXltZWRp
          YS5jb22CG3dvcmtlci0wMDQubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwNS5t
          bmNwbGF5bWVkaWEuY29tght3b3JrZXItMDA2Lm1uY3BsYXltZWRpYS5jb22CG3dv
          cmtlci0wMDcubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwOC5tbmNwbGF5bWVk
          aWEuY29tght3b3JrZXItMDA5Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTAu
          bW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAxMS5tbmNwbGF5bWVkaWEuY29tght3
          b3JrZXItMDEyLm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTMubW5jcGxheW1l
          ZGlhLmNvbYIbd29ya2VyLTAxNC5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE1
          Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTYubW5jcGxheW1lZGlhLmNvbYIb
          d29ya2VyLTAxNy5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE4Lm1uY3BsYXlt
          ZWRpYS5jb22CG3dvcmtlci0wMTkubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAy
          MC5tbmNwbGF5bWVkaWEuY29thwR/AAABhwQKZAABhwQKCThlhwQKCThmhwQKCThn
          hwQKCThohwQKCThphwQKCThqhwQKCThrhwQKCThshwQKCThthwQKCThuhwQKCThv
          hwQKCThwhwQKCThxhwQKCThyhwQKCThzhwQKCTh0hwQKCTh1hwQKCTh2hwQKCTh3
          hwQKCTh4hwQKCTh5hwQKCTh6hwQKCTh7MA0GCSqGSIb3DQEBCwUAA4IBAQBgIAfQ
          8iygIRCEqj6R//7qHRo506U6QJjxbtveaBhvDR4P5k0V/6t/8RN46NlkWVnT8ghe
          V5Pu0UBaoylhE16Eg2HFrDc4q64zW4WNDePBqWHaQykzOvB2MQLSmqSKWCIv1wvh
          ioaW6VOlNsrF1jKOaN/It9BpGqMzQInU9VHHGoI8Im57zD8qY7NGoPA+2BWcwHfl
          +OO5YWcHib0Z1MbSTewuuRFGAeq6fLr341u7d/K51ycrwC9XrygOvRctAEE4PQNM
          6lvxk7sAwyOXm6WgpE9qwGQw7HrMzRdjNF/XEqmUmylrKNNJCKJiQ/+zWcmAvMyX
          6Ifl783SfZ9Oys72
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-proxy-master-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEpAIBAAKCAQEA3/fv8ok4ZKLXmJCW5hj9U56uqvdvHZiS88sM6r5U+qUEXBAD
          erUEgkwchjNUB2tV2ONqokRf7mjLnGf0zLM80HHQwZXy5Wy54FB1WHN+DlgKqCL+
          BzUOP7H49jbvvObCS8kLRpjO0sn85MjbRW5eDf9C63gsceA83aAeZuPwuxdTc0qv
          NPcUmfAP/Cvhqp2W7F15YVpns6Wi9k9nhr2qWmiz7/fTAxwy6DxI+ZQ4zkZ7+SbM
          4ZHGIQ+ivDM1hpl2+IJbs3AGGJwZzwbWeTXJgFpNXE+zOxixBsRrZSrqPUh/+RJW
          zFdk/4h/tVM0llBTmUvXSC8X4ZIrMlLlWpr9KQIDAQABAoIBACldWWup/EhZ6we6
          bKRCqUbwX8IjwNnue/Wa4t/YF0nTgGKgcoQPOq318K64fCSCpnBQUDl391/I6xIQ
          AR5tXCYDX1LhpuLImevb8FBNxFJR4GX9UH10RxVsgVa3/r8cv3XPw81eG5TCyXpX
          vmesYqKjKnDi2RKPH66vC+5k2ukypSoUzooOsr3tsLM9HmssYbGwNCbeteNuXGkN
          cvW4EbRnGX4J4SwMPwoRlMs5YBOzpEFqASOGEUwssVqLDYH4mXJLZ0aVsiHayVxg
          Zb/Uc9loUTdhKhf6ZuwD6o+AKTz0lmmoJ9jn7frIZ3xMOxm/7ZjYhy81ee6Bc5vT
          UY4by6ECgYEA+S/iq7yD7WRHd2CQqiL5Sf7mRFQ6DEx2Rb2vCLQcr+7bdK8wiHNu
          SdtgTCZr7O1zmu3RsFKePZN1KNvfzQZcoNqgr6C8nO5wLaK6OcjkeOhlaqp+YC8j
          U9mQTaKFJgAcjBivPbokERAh7uAraPzUspVTT9OS0ocGJnnE8R4z3vcCgYEA5heK
          r72KvVyQxJSLyN3f7NzYCRQsGbVEAorRhddNZ8xRObreqFePOEWHPgjVJjVYYQWd
          0E0mMQd4WZM/GmSyslqw6MYd/ea50EXPsoLBlgLNk1iZSbdutC3SAp20TVomot3h
          Hs0r6BjjjoiZLBYelSe2M7T6Jybeix+ewqFNXN8CgYEAzy0Y8GAT79Nn98C5hjr9
          uJ/NIxJEEOWhj+pdFIdrMnsMyr69QzV1hMJ4Fdf780iYzT7dEBQgrGFlD0t/jx6y
          9KnQ3zRsnK1BZy/cVR7Jlhzh9QU7fQyz+orwhxuQSD/ffDspt9CDHAylqc2HSgqr
          bK7qTXxCnfbVDjg/nZjW15ECgYByn3evZLUg8GQOChI41o8e6EWXAD2X8P0YZx9J
          laAx/U7Ze4ZARp5KYhilhrDof9qvOqULh+NmuVnzBa+B7ng28Yb/7vIx8ibO4ng9
          bXYSzQKsTI7Qcljr2YetVfLkNezZZb8oIP2mef+imdn0ZHCHzWivCZE0v+BNXksw
          mjp38QKBgQC4ui2jFkOR8/RNQZRpUlcXJixXxKU8gcutMhVTCA8bDhXTJf+JueyP
          zhCbkABR8Xz4VhgAfH+jNUO8NxNW8XoLl5vDgSSwEhVz0oU35AaKg7XQTlekcIdP
          GE3wGOgkZc32kgafzR6+0ghJMtpmAhV64GwD9eU2GRLnR9VKB4Z5fw==
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-proxy-master.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIFPTCCBCWgAwIBAgIUAzguuTXqzhq9k932l6+LqSAMw/EwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTQw
          MFoXDTI5MDYzMDIzMTQwMFowgY0xCzAJBgNVBAYTAlVTMQ8wDQYDVQQIEwZPcmVn
          b24xETAPBgNVBAcTCFBvcnRsYW5kMRwwGgYDVQQKExNzeXN0ZW06bm9kZS1wcm94
          aWVyMSAwHgYDVQQLExdLdWJlcm5ldGVzIFRoZSBIYXJkIFdheTEaMBgGA1UEAxMR
          c3lzdGVtOmt1YmUtcHJveHkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIB
          AQDf9+/yiThkoteYkJbmGP1Tnq6q928dmJLzywzqvlT6pQRcEAN6tQSCTByGM1QH
          a1XY42qiRF/uaMucZ/TMszzQcdDBlfLlbLngUHVYc34OWAqoIv4HNQ4/sfj2Nu+8
          5sJLyQtGmM7SyfzkyNtFbl4N/0LreCxx4DzdoB5m4/C7F1NzSq809xSZ8A/8K+Gq
          nZbsXXlhWmezpaL2T2eGvapaaLPv99MDHDLoPEj5lDjORnv5JszhkcYhD6K8MzWG
          mXb4gluzcAYYnBnPBtZ5NcmAWk1cT7M7GLEGxGtlKuo9SH/5ElbMV2T/iH+1UzSW
          UFOZS9dILxfhkisyUuVamv0pAgMBAAGjggGiMIIBnjAOBgNVHQ8BAf8EBAMCBaAw
          HQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMAwGA1UdEwEB/wQCMAAwHQYD
          VR0OBBYEFNAEWurYMED9D7Ojlj5osqNj7LLgMB8GA1UdIwQYMBaAFL0E08PW2vwH
          1/DKI7dCyBC0oKzZMIIBHQYDVR0RBIIBFDCCARCCCmt1YmVybmV0ZXOCEmt1YmVy
          bmV0ZXMuZGVmYXVsdIIWa3ViZXJuZXRlcy5kZWZhdWx0LnN2Y4Iea3ViZXJuZXRl
          cy5kZWZhdWx0LnN2Yy5jbHVzdGVygiRrdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNs
          dXN0ZXIubG9jYWyCG2t1YmVybmV0ZXMubW5jcGxheW1lZGlhLmNvbYIbbWFuYWdl
          ci0wMS5tbmNwbGF5bWVkaWEuY29tghttYW5hZ2VyLTAyLm1uY3BsYXltZWRpYS5j
          b22CG21hbmFnZXItMDMubW5jcGxheW1lZGlhLmNvbYcEfwAAAYcECmQAAYcECgk4
          ZYcECgk4ZocECgk4ZzANBgkqhkiG9w0BAQsFAAOCAQEAmp4ZAQBejpXVY3GThnEb
          Sju9C1VZKOGaOQO1QOKodugOcDLI+8brDiSCr6pV3Itd71TLCA5bTK7DYk5efNc3
          qpCueFOmM4/E9JTcXoQzlbVJDbznj9MPrljM9DOLD+lFtOdpGk8/o+4qtMSrYa1m
          QijieOs0x6HURWHRUKN5NL2dBQNKf90z53FqMd0+i7x0IjMIgYQcFrtGOsZLRUTZ
          Z+MojgwaBNymGauK/mrbqw5T+HoZkkyajlSe8u8aBcM6Xkqnj0k9fJIB1ERMyMOq
          /ZVibDrInbYT8sVAvpd3aJH6Gc7ot4BMxRTI243XLLADGtqNm2iqPKxm7ujvmJbZ
          5A==
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-controller-manager-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEpAIBAAKCAQEAzfSyaNNMqw9SQR/uPwEKx/7a6nxYYkSqA/+CgI9HFbN7DEK4
          oD4uD9UVyPTWPYrbpTax4Ah8gTwIYqliqIOK+Ssg4N6zaS2nGvX72/XwfCQSZOxn
          5l6efNnaHaBmpp5yrZx4ou/w0z8fXBO6kXOdYRaI9HUlSTdB1XZuwIyiEj4tCa/k
          myMhldiGwQf9+ZN28oEmDE4EAKwcZj7YYaa1ZH3klalzHHV/3JwJj/VlnTjGh/do
          zPEYOPetFy+Zfiwgy8KS8zw1QnpNjHP5/wph6/I4GNz6QbuygmE4/M25KnXEz06Y
          zkowX8uUr3Y4haYWc16zpVHrqdkUDprxHsOYpwIDAQABAoIBAQCKPUWHMNTUOLt4
          NQuARJ3M8dZU79OPWhFYD6ezzPfkrAzahOpRvIrEW718nkIzGsIlWdn4yxlu0TG7
          r4AmJe0hI/60kSaRYXA5m4RK9wBNAxVJoph2u2nb2YoaurBMBCxrNYyPqUfXMxZE
          goWG3bh0E2En3H2DcFCDDDR4j6y1WstA/EqhwTydHMvhmTgkmUEh1DcrweoH5FgS
          d+8jvBtEFSC/B2ON7ZOwrqfGvFn1SkDBgF9tBHx44Hz+wa9cPNtpeP/rASbDqlOj
          wWAVnroXS5ciF5CF3QBRa5B1JqSxDQzeWKmZuRWisQwxQESCAg9Gv+AFwf5S6W/N
          BEnuk9NhAoGBANQ0yR1FSH3wrZm3e1fGu4WwqHfpQrzVCb13fdOR1m7Iu8TC9+aq
          NEjtyrVyFt5D6IeVFVSuK2q1FsxtV6cnomzwbZOiiiIdZ8dReIOTET0Shfstf1Oz
          LSDJhFWucMthjvHigxB+gZBA/I9s8zbRixrgUMYV5a2nzFonVoOkHNz3AoGBAPh1
          seLeKBK79Ho5p2jO7gAaRVaybv+r6JRCUW9z5ZTdLiw0z9SjFihFjq9srBX8BIPC
          9qbEV2MS9dK90AUE/2mem4dvvjLMg7DzrhRuRegZFe4limlj1nVI8LXWxNVkAJaC
          T2Br72NS62dRptnoQfeAdbR+ueegsEbwjJFzeKXRAoGBAKBQjItvdxemBxC1HBqx
          CaQzVOLaN0//Rg98QXPfnnctcSVyAeSiO0PJWbYATiR2eypKx8WkmypPSrz/8hNX
          Dw9sB+xcBC1Ht8pN01Tbe09/OfcLZUDvgS1e8HnmglI0DtDQRiHk4K8BWYxlS8zj
          O0r/oiY0DsNFnE2ToHltN1z7AoGARhoXDba2wcpsSUwZEvZHqpm+9J41uUeMwMAR
          cAvYO+9IBssD1LALIWO2xYI4758CuxZ4N0dwjJCd8U8C8VeepPNOWKFLndOcWIH4
          nOUcLkddq6rF6cR0jvT8jaHCOZ8Ul2K++KqbiX+s0aL1G8hvTGDfVQToeRUah3l5
          f9R/tvECgYAqgNdlikMYnrPcciKkXku30UuVqBx5sSkVGTm8ssVXc+rNOp8jd7Or
          ShVkn8lJkYXjPaKgNr3YDTwMSDNL9hZZhCY2DB8acmRSjWYpyRQ1GLfhSiH2ERgY
          9qOP/9zrpFAfUzb4R2ZoXgiVQL4zqAVv1KA2+p1hs/dUwp8Rf3Tf7Q==
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-controller-manager.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIEMDCCAxigAwIBAgIUTw/QuQL6BaXMA+iNEBRb/VkewpEwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTIw
          MFoXDTI5MDYzMDIzMTIwMFowgaUxCzAJBgNVBAYTAlVTMQ8wDQYDVQQIEwZPcmVn
          b24xETAPBgNVBAcTCFBvcnRsYW5kMScwJQYDVQQKEx5zeXN0ZW06a3ViZS1jb250
          cm9sbGVyLW1hbmFnZXIxIDAeBgNVBAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5
          MScwJQYDVQQDEx5zeXN0ZW06a3ViZS1jb250cm9sbGVyLW1hbmFnZXIwggEiMA0G
          CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN9LJo00yrD1JBH+4/AQrH/trqfFhi
          RKoD/4KAj0cVs3sMQrigPi4P1RXI9NY9itulNrHgCHyBPAhiqWKog4r5KyDg3rNp
          Laca9fvb9fB8JBJk7GfmXp582dodoGamnnKtnHii7/DTPx9cE7qRc51hFoj0dSVJ
          N0HVdm7AjKISPi0Jr+SbIyGV2IbBB/35k3bygSYMTgQArBxmPthhprVkfeSVqXMc
          dX/cnAmP9WWdOMaH92jM8Rg4960XL5l+LCDLwpLzPDVCek2Mc/n/CmHr8jgY3PpB
          u7KCYTj8zbkqdcTPTpjOSjBfy5SvdjiFphZzXrOlUeup2RQOmvEew5inAgMBAAGj
          fzB9MA4GA1UdDwEB/wQEAwIFoDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUH
          AwIwDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUg5YDGB/19fcGwGoxnZS5M0Hjnscw
          HwYDVR0jBBgwFoAUvQTTw9ba/AfX8Mojt0LIELSgrNkwDQYJKoZIhvcNAQELBQAD
          ggEBAJJFFUY06GQbcjsHXCRhENU/R8Nh7iCG6i/2OfdiDVUxLdy4llkqRGHSAUV1
          b4MyeMArRU/acBTgmkuixt7go6vBnpmRo1V8mLOVwwJG046VTdLKFKbOHH9tGr9P
          ihllPep3LBYXC8BJjfqrTZ4HQGML5Asjk7Ken63O3ZvWSAsR1J2HjvMZZ2Td8UhD
          1tHYYWK0fdeCuajk0Y1ScBPViB+Seao462a/MX/JsukSfFE0FWKEcFzj94Z/0PT8
          l59EWMn1sukmBO2xCt0L+eKxjTAqHWDMelfbwjy5iy1O33Xnofg378BoHzri4Hbc
          4fMM8WeBFv1nHez7UVc3gmkz+FM=
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-scheduler-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEowIBAAKCAQEArKNgBeXLrOJyXtumqfLpWxdj1omnGdaqetY3kncXOTm1Ig/t
          dnMZ8xK/XFV4W81tqQevcbZeolViD4Ii1frgq/TRJZiD/C4VgLktSAZ+7h7IAnSw
          3ns0ZzzZAzBYcC24ZaftarN4J29MWMvOPT4K4Hd4Ah/GEsWo8/I+o1Ru3qPCN2Vl
          p+wLTyS8s80C6m6kS9Ne+SqF4peNRSTLXVcYy2al2QdmWL4jN1EndJjHZ0Kfncvq
          rrqgrEzHF1CYXJllE44hLTI8doRVLAOJwFtSldd2lKvtAIe2oLSts5vxVndfFqcH
          7PPC1tFFhUBVO2Xs1SgUYIsU58s+ZD4mLS46BwIDAQABAoIBACUVm0TpDg1/P049
          JNoRAiu9JIcrXqfgQxLL/XgK+QQj71L31OzC4OokNtMg0Q/3Wv0aV4e3wzBf4wat
          z8njcGu/1UWcM43yYFAcdyunqZCBMDnG00+Xa7RZj8xtkDHYwGml3wwyrTbbY60X
          aqAhObjqMO9T3/qcVyS//tCbDI3qiQXryUCI1uH9ERkhkmOszAsFlGDL0IID8xIj
          EICOcIdsKAvZ21U+rC0xmlH4S0EK5L4TGG3zkYXJUXuIz4617g3Z6n5uMacFpBmI
          AVSbbdon9luldshJQsjOYlce71oVjqNuiIiv/xwXP0U9NGxLDaY8jwRmGc0rf933
          9hLh0HECgYEAxRPgNyyibW7584HQajBih/bBVt/bzMmkoydhNp3ifKQCSWlPESAm
          MxncgCaSB1mgVFIxRTpKQcD4JMhrUHgAEeHq27zQMhc5ehgRJUuK3vauiwmVQljp
          1kp7KuK0aOvRvORg/Ua1ZlO3YBNh5jozf6E5kzxBD/cRLcfw0+Eq5NUCgYEA4EDt
          iegskZFkqlCGOZAznMD7yOtexjrMx78FUv/+NbSZgWxgOeNYTZXXJiq8ykjy5CwT
          Rb/eLYF7apyu473yvfC4Uo/UWJ2kMYqnF+OLH9Xl9K3S8KtTVlDkwDcvygHjaTmP
          +uEmwv9widKsirDCOthQmsz70p6CeXizOeDMwWsCgYAZWNYUopP9eTGCpSaWEcUK
          ca0qLD6L1z9qkI0LRkE0ALAemwHFVRo0plXa0ZskgN2DGtMlcTrNvDDuIizTO6ve
          oOzg+Cba2mvVDTVfU5j31khar4/X6bGhkxDGUkQb3oCqR8FFsgtwrsG+BKApyUCI
          YMcT7cL8d61o8vdBeQtYRQKBgEjP7BCN6QKuwY+nK52/G3L3GgmHmrMkXl8wv6rO
          YZzQcdMa/DdvgLlYQI4s7DWF8A9z3CIWhS4jT44zJ3ncr9dKNJ7iAmFvdeN8EHrq
          L777dXm3grkP97Qb+doLUSH28P62aPBdcHd59vFZDRrO/5GZsLpCejVNsDF+pjrR
          qcnXAoGBAI/Sz+Unx7YF1uJWquU6UhqXT/QWs3kqJ04ueHhFMDiHbwgsU18OYcQl
          GNdyDiOWHA8TyEG0w2RJiWGDWwT1wxH6qXT3J2PPxkpNIUfHWtoVxbZp6DPj/4gv
          NkdlNdQKFtS9nxM3+ZF6zoGk2uE69hoZ9+wDimrplyTsajlk+/zj
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/kubernetes/ssl/kube-scheduler.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIEHjCCAwagAwIBAgIUFF80wycY6zTX9OvpPl1FRJaFf8swDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTUw
          MFoXDTI5MDYzMDIzMTUwMFowgZMxCzAJBgNVBAYTAlVTMQ8wDQYDVQQIEwZPcmVn
          b24xETAPBgNVBAcTCFBvcnRsYW5kMR4wHAYDVQQKExVzeXN0ZW06a3ViZS1zY2hl
          ZHVsZXIxIDAeBgNVBAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MR4wHAYDVQQD
          ExVzeXN0ZW06a3ViZS1zY2hlZHVsZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw
          ggEKAoIBAQCso2AF5cus4nJe26ap8ulbF2PWiacZ1qp61jeSdxc5ObUiD+12cxnz
          Er9cVXhbzW2pB69xtl6iVWIPgiLV+uCr9NElmIP8LhWAuS1IBn7uHsgCdLDeezRn
          PNkDMFhwLbhlp+1qs3gnb0xYy849Pgrgd3gCH8YSxajz8j6jVG7eo8I3ZWWn7AtP
          JLyzzQLqbqRL0175KoXil41FJMtdVxjLZqXZB2ZYviM3USd0mMdnQp+dy+quuqCs
          TMcXUJhcmWUTjiEtMjx2hFUsA4nAW1KV13aUq+0Ah7agtK2zm/FWd18Wpwfs88LW
          0UWFQFU7ZezVKBRgixTnyz5kPiYtLjoHAgMBAAGjfzB9MA4GA1UdDwEB/wQEAwIF
          oDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAd
          BgNVHQ4EFgQUdBWyvL24Pk9pGY+Ulf3pdm1gNncwHwYDVR0jBBgwFoAUvQTTw9ba
          /AfX8Mojt0LIELSgrNkwDQYJKoZIhvcNAQELBQADggEBACE+1FLk4kcr5ME8JDme
          SzSlq3QuFmi5YS12s6ZWhqz4nm9K//5JibZ/oOn9CPoZZ4J7jtFmUwWWEs6Et5is
          qj4p7uo22IHZMhcdOTXjKDyzcu7a/VvHW4iJHhtbdEwVPgTmuUW3XNflskewYmkV
          uylbw15z8CMXWnxm6gPEE4j9+Zas37B6KvnH2j1RIK7uLsygJHcDPUG0OJP0eJ2G
          VbXXw7I8KD5eepjf+PyB+AZAmy/eiqbjmuTzYDr5G2kznocWnao0ADBUy6VMHc0y
          ogRXfMMfMspMe4gbhZ+BdAxCsbvL9DzaSc2TTlbKoPzAVMIKGEB9ffs2BmyTLZ0T
          ccA=
          -----END CERTIFICATE-----
    
    # kube-proxy file.
    - filesystem: "root"
      path: "/var/lib/kubeproxy/kube-proxy-config.yaml"
      mode: 0644
      contents:
        inline: |
          apiVersion: kubeproxy.config.k8s.io/v1alpha1
          kind: KubeProxyConfiguration
          bindAddress: 0.0.0.0
          clientConnection:
            kubeconfig: "/etc/kubernetes/ssl/kubeconfig-kube-proxy-master.yaml"
          mode: "ipvs"
          clusterCIDR: "10.244.0.0/17"
              
    - filesystem: "root"
      path: "/etc/profile.d/locksmithctl.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          export LOCKSMITHCTL_ETCD_CAFILE=/etc/ssl/certs/ca.pem
          export LOCKSMITHCTL_ETCD_CERTFILE=/var/lib/etcd/ssl/etcd-node.pem
          export LOCKSMITHCTL_ETCD_KEYFILE=/var/lib/etcd/ssl/etcd-node-key.pem
          export LOCKSMITHCTL_ENDPOINT="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
    
    - filesystem: "root"
      path: "/etc/profile.d/etcdctl.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          export ETCD_TRUSTED_CA_FILE=/etc/ssl/certs/ca.pem
          export ETCD_DATA_DIR=/var/lib/etcd
          export OCTANT_LISTENER_ADDR=0.0.0.0:8900
          
    - filesystem: "root"
      path: "/opt/bin/scripts/check_etcdv3_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" member list --write-out table"
          ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" member list --write-out table
          echo "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" --write-out=table endpoint status"
          ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" --write-out=table endpoint status
          echo "========================================================================================================================================================================================"
          echo "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" member list"
          echo "========================================================================================================================================================================================"
          ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" member list
          echo "===================================================================================================================================================================================="
          echo "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" version"
          echo "===================================================================================================================================================================================="
          ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" version
          echo "=============================================================================================="
          echo "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem \ "
          echo "--key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints=https://10.9.56.102:2379 endpoint health"
          echo "=============================================================================================="
          ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/certs/ca.pem --cert=/var/lib/etcd/ssl/etcd-node.pem --key=/var/lib/etcd/ssl/etcd-node-key.pem --endpoints="https://10.9.56.102:2379" endpoint health
          echo "============================"
          echo "sudo rkt list | grep running"
          echo "============================"
          sudo rkt list | grep running
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_service_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "======================================="
          echo "systemctl --type=service | grep running"
          echo "======================================="
          systemctl --type=service | grep running
          echo "=========================================="
          echo "systemctl --type=service | grep -v running"
          echo "=========================================="
          systemctl --type=service | grep -v running
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_iptables_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "======================================="
          echo "sudo iptables -t nat -L -n"
          echo "======================================="
          sudo iptables -t nat -L -n
          echo "======================================="
          echo "sudo netstat -tunlp"
          echo "======================================="
          sudo netstat -tunlp
          echo "======================================="
          echo "sudo ip route"
          echo "======================================="
          sudo ip route
          echo "======================================="
          echo "sudo route"
          echo "======================================="
          sudo route
          echo "======================================="
          echo "sudo netstat -i"
          echo "======================================="
          sudo netstat -i
          echo "======================================="
          echo "sudo brctl show"
          echo "======================================="
          sudo brctl show
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_k8s_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "======================================="
          echo "sudo kubectl get cs"
          echo "======================================="
          sudo kubectl get cs
          echo "======================================="
          echo "sudo kubectl cluster-info"
          echo "======================================="
          sudo kubectl cluster-info
          echo "======================================="
          echo "sudo kubectl get nodes --show-labels"
          echo "======================================="
          sudo kubectl get nodes --show-labels
          echo "======================================="
          echo "sudo kubectl get nodes -o wide"
          echo "======================================="
          sudo kubectl get nodes -o wide
          echo "======================================="
          echo "sudo kubectl version"
          echo "======================================="
          sudo kubectl version
          echo "======================================="
          echo "sudo kubectl get endpoints kubernetes"
          echo "======================================="
          sudo kubectl get endpoints kubernetes
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_kubectl_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "======================================================================================"
          echo "sudo kubectl get deploy,rc,rs,svc,pv,pvc,po,DaemonSet,ingress -o wide --all-namespaces"
          echo "======================================================================================"
          sudo kubectl get deploy,rc,rs,svc,pv,pvc,po,DaemonSet,ingress -o wide --all-namespaces
          
    - filesystem: "root"
      path: "/opt/bin/scripts/check_ipvsadm_status.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "======================================"
          echo "sudo ipvsadm -ln"
          echo "======================================"
          sudo ipvsadm -ln
          echo "======================================"
          echo "sudo ipvsadm -l -c"
          echo "======================================"
          sudo ipvsadm -l -c
          echo "========================================"
          echo "sudo ipvsadm -l --timeout"
          echo "========================================"
          sudo ipvsadm -l --timeout
          echo "========================================"
          echo "sudo ipvsadm -l --stats"
          echo "========================================"
          sudo ipvsadm -l --stats
          echo "========================================"
          echo "sudo ipvsadm -l --rate"
          echo "========================================"
          sudo ipvsadm -l --rate
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_config.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          echo "==========================================================================================="
          echo "sudo kubectl config get-clusters --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml"
          echo "==========================================================================================="
          echo "============"
          echo "get-clusters"
          echo "============"
          sudo kubectl config get-clusters --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          echo "=============================================================================================="
          echo "sudo kubectl config current-context --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml"
          echo "=============================================================================================="
          echo "======================"
          echo "config current-context"
          echo "======================"
          sudo kubectl config current-context --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          echo "==========================================================================================="
          echo "sudo kubectl config get-contexts --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml"
          echo "==========================================================================================="
          echo "============"
          echo "get-contexts"
          echo "============"
          sudo kubectl config get-contexts --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
          echo "==================================================================================="
          echo "sudo kubectl config view --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml"
          echo "==================================================================================="
          echo "==========="
          echo "config view"
          echo "==========="
          sudo kubectl config view --kubeconfig=/etc/kubernetes/ssl/bootstrap.kubeconfig.yaml
    
    - filesystem: "root"
      path: "/opt/bin/scripts/check_ceph_disk.sh"
      mode: 0755
      contents:
        inline: |
          #! /usr/bin/bash
          POD_NAME=$(sudo kubectl get pods -o wide -n rook-ceph -l app=rook-ceph-tools -o jsonpath="{.items[0].metadata.name}")
          echo "=============================================================="
          echo "rook.io ceph status"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph status
          echo "=============================================================="
          echo "rook.io ceph osd status"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph osd status
          echo "=============================================================="
          echo "rook.io ceph osd disk status"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph osd df
          echo "=============================================================="
          echo "rook.io ceph osd utilization"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph osd utilization
          echo "=============================================================="
          echo "rook.io ceph osd pool stats"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph osd pool stats
          echo "=============================================================="
          echo "rook.io ceph osd tree"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph osd tree
          echo "=============================================================="
          echo "rook.io ceph pg stat"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph pg stat
          echo "=============================================================="
          echo "rook.io ceph cluster total disk size"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- ceph df
          echo "=============================================================="
          echo "rook.io ceph cluster total disk size from rados"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- rados df
          echo "=============================================================="
          echo "rook.io version"
          echo "=============================================================="
          sudo kubectl exec -n rook-ceph -it $POD_NAME -- rook version
          
    - filesystem: "root"
      path: "/etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf"
      mode: 0644
      contents:
        inline: |
          [Service]
          ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
          ExecStartPre=/usr/bin/ln -sf /etc/kubernetes/ssl /etc/kubernetes/pki
    
    - path: /etc/systemd/system/docker.service.d/environment.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          [Service]
          EnvironmentFile=/etc/environment
          
    - path: /etc/systemd/timesyncd.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          [Time]
          NTP=0.coreos.pool.ntp.org 1.coreos.pool.ntp.org 2.coreos.pool.ntp.org 3.coreos.pool.ntp.org
    
    - path: /etc/ntp.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          server 0.coreos.pool.ntp.org
          server 1.coreos.pool.ntp.org
          server 2.coreos.pool.ntp.org
          server 3.coreos.pool.ntp.org

          # - Allow only time queries, at a limited rate.
          # - Allow all local queries (IPv4, IPv6)
          restrict default nomodify nopeer noquery limited kod
          restrict 127.0.0.1
          restrict [::1]
          
    - path: /etc/timezone
      filesystem: root
      mode: 0644
      contents:
        inline: Asia/Jakarta
          
    - path: /etc/profile.d/aliases.sh
      filesystem: root
      mode: 0755
      contents:
        inline: |
          check-etcd () { /opt/bin/scripts/check_etcdv3_status.sh ; }
          check-service () { /opt/bin/scripts/check_service_status.sh ; }
          check-iptables () { /opt/bin/scripts/check_iptables_status.sh ; }
          check-kubectl () { /opt/bin/scripts/check_kubectl_status.sh ; }
          check-config () { /opt/bin/scripts/check_config.sh ; }
          check-ipvsadm () { /opt/bin/scripts/check_ipvsadm_status.sh ; }
          check-k8s () { /opt/bin/scripts/check_k8s_status.sh ; }
          check-ceph () { /opt/bin/scripts/check_ceph_disk.sh ; }
          sjf () { sudo journalctl -f ; }
          dim () { docker images ; }
          dps () { docker ps ; }
          PATH=$PATH:/opt/bin
    
    - filesystem: "root"
      path: "/etc/kubernetes/cni/net.d/99-loopback.conf" 
      mode: 0644
      contents:
        inline: |
          {
             "cniVersion": "0.3.1",
             "type": "loopback"
          }
          
    - filesystem: "root"
      path: "/etc/kubernetes/cni/net.d/10-containernet.conf"
      mode: 0644
      contents:
        inline: |
          {
            "name": "podnet",
            "type": "flannel",
            "subnetFile": "/var/run/flannel/subnet.env",
            "delegate": {
               "bridge": "cni0",
               "mtu": 1440,
               "forceAddress": true,
               "hairpinMode": true,
               "isDefaultGateway": true
            }
          }
          
    - filesystem: "root"
      path: "/etc/rkt/net.d/99-loopback.conf" 
      mode: 0644
      contents:
        inline: |
          {
             "cniVersion": "0.3.1",
             "type": "loopback"
          }
          
    - filesystem: "root"
      path: "/etc/rkt/net.d/10-containernet.conf"
      mode: 0644
      contents:
        inline: |
          {
            "name": "podnet",
            "type": "flannel",
            "subnetFile": "/var/run/flannel/subnet.env",
            "delegate": {
               "bridge": "cni0",
               "mtu": 1440,
               "forceAddress": true,
               "hairpinMode": true,
               "isDefaultGateway": true
            }
          }
    
    - filesystem: "root"
      path: "/etc/cni/net.d/99-loopback.conf" 
      mode: 0644
      contents:
        inline: |
          {
             "cniVersion": "0.3.1",
             "type": "loopback"
          }
          
    - filesystem: "root"
      path: "/etc/cni/net.d/10-containernet.conf"
      mode: 0644
      contents:
        inline: |
          {
            "name": "podnet",
            "type": "flannel",
            "subnetFile": "/var/run/flannel/subnet.env",
            "delegate": {
               "bridge": "cni0",
               "mtu": 1440,
               "forceAddress": true,
               "hairpinMode": true,
               "isDefaultGateway": true
            }
          }
          
    - filesystem: "root"
      path: "/etc/environment"
      mode: 0644
      contents:
        inline: |
          COREOS_PUBLIC_IPV4=10.9.56.102
          COREOS_PRIVATE_IPV4=10.9.56.102
          COREOS_HOSTNAME=manager-02.mncplaymedia.com
          ETCD_SSL_DIR=/var/lib/etcd/ssl
          ETCD_ENDPOINTS="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
          FLANNELD_ETCD_ENDPOINTS="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
          FLANNELD_IFACE="ens32"
          FLANNELD_ETCD_PREFIX="/coreos.com/network"
          LOCKSMITHCTL_ETCD_CAFILE=/etc/ssl/certs/ca.pem
          LOCKSMITHCTL_ETCD_CERTFILE=/var/lib/etcd/ssl/etcd-node.pem
          LOCKSMITHCTL_ETCD_KEYFILE=/var/lib/etcd/ssl/etcd-node-key.pem
          LOCKSMITHCTL_ENDPOINT="https://10.9.56.101:2379,https://10.9.56.102:2379,https://10.9.56.103:2379"
          OCTANT_LISTENER_ADDR=0.0.0.0:8900
          no_proxy=localhost,127.0.0.0/8,127.0.0.1,::1,10.9.56.101,10.9.56.102,10.9.56.103,manager-01,manager-02,manager-03,manager-01.mncplaymedia.com,manager-02.mncplaymedia.com,manager-03.mncplaymedia.com,mncplaymedia.com,/var/run/docker.sock
          
    - filesystem: "root"
      path: "/etc/systemd/system.conf.d/10-default-env.conf"
      mode: 0644
      contents:
        inline: |
          [Manager]
          DefaultEnvironment="localhost,127.0.0.0/8,127.0.0.1,::1,10.9.56.101,10.9.56.102,10.9.56.103,manager-01,manager-02,manager-03,manager-01.mncplaymedia.com,manager-02.mncplaymedia.com,manager-03.mncplaymedia.com,mncplaymedia.com,/var/run/docker.sock"
    
    - filesystem: "root"
      path: "/root/.bashrc"
      mode: 0655
      contents:
        inline: |
          if [[ $- != *i* ]] ;then
              return 
          fi
          
          alias csysdig="docker run -i -t --rm --privileged -v /var/run/docker.sock:/host/var/run/docker.sock -v /dev:/host/dev -v /proc:/host/proc:ro sysdig/sysdig csysdig -pc"
          alias sysdig="docker run -i -t --rm --privileged -v /var/run/docker.sock:/host/var/run/docker.sock -v /dev:/host/dev -v /proc:/host/proc:ro sysdig/sysdig sysdig"
    
    - filesystem: "root"
      path: "/etc/ssl/certs/ca.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIEljCCA36gAwIBAgIUU+WUWXU2Eb2mgs7Rr1G0ffEA/IAwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTEw
          MFoXDTI0MDcwMTIzMTEwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtLFdH094CypU7j6r8ToK
          J+KsLnDw1RNNHb/Qp2+wWailXQ8Haby4QcJKbt1zAwJceNvP6iMFPypp8FB0tIZO
          Icvoq16QkztOnlrg7CMvdutdhlzehefxXFrHaNnekOA/Ss8uvyH7Z5bj7+BmmrtA
          o0jzzh12RS+qIwnBYLgSr01jRKV3F868tPG273Yyb+HaCQTQWXoGfVfiT1va6zB/
          IEXlWt/K0FmM7uMyVPlAlxq214NSdaEz+e8qORuLp5EhZp58cwSotLxAcdYdRurI
          yPnGwZ4cjvTg97FH55fhQ+x7jkSXs09Hbq95yEtBJ9RWL83SHr2mckIQM+MSzJel
          qwIDAQABo4IBDDCCAQgwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8C
          AQIwHQYDVR0OBBYEFL0E08PW2vwH1/DKI7dCyBC0oKzZMB8GA1UdIwQYMBaAFL0E
          08PW2vwH1/DKI7dCyBC0oKzZMIGhBgNVHREEgZkwgZaHBH8AAAGHBApkAAGHBAoJ
          OGWHBAoJOGaHBAoJOGeHBAoJOGiHBAoJOGmHBAoJOGqHBAoJOGuHBAoJOGyHBAoJ
          OG2HBAoJOG6HBAoJOG+HBAoJOHCHBAoJOHGHBAoJOHKHBAoJOHOHBAoJOHSHBAoJ
          OHWHBAoJOHaHBAoJOHeHBAoJOHiHBAoJOHmHBAoJOHqHBAoJOHswDQYJKoZIhvcN
          AQELBQADggEBADYGbExdzqhRXOdFSNswme8w61qiMfdEDYfiqk1VnEiU5A8jCeZe
          AeTt5LJHhxVh5uu6LiGzBQPbLahF9MrBw0dty4f85NugN2dca/gUxy70GjHeZatS
          WpTthLV9vQ0SU6tgzT4tItzInK0o7jev10IEcgqozoG2Tj3f0CwBnj72moz1681B
          zwfAn3RhmqiVU9uh1tyXFfqTcfVHq4f/Qj/+F5621VbNWFQwkypy27O4SyRYM0b9
          wWsxCXXfQPCTVcd69XRu4dKWhL7X9z+0CGkeEFwE515pYzcOB1dWnTDo+DW2g6av
          S8utxK8/C4qecEL3p4DLqHwMgpKl/89L0JI=
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/var/lib/etcd/ssl/etcd-node.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIH6DCCBtCgAwIBAgIULy3KnguWZtIbB2ugQjgRjyct9YIwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTYw
          MFoXDTI5MDYzMDIzMTYwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwge2SUSbIB1jHYgHtrpN
          DaogTbqwjVLWgXJw6yUpzM9cRr7MPG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4h
          euxmKj4AHw/ndNXrb6xiYELuUwE8dcrLab2ImnY2YyDE3I30uaUWcgH683pm/Gdm
          GHoLwroyTnoa0b246pAj6eQU4nqeH3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QT
          KtYyCn4uKjmdoN95g8el1rak5D17s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6N
          x4U5zY8XUns/ArjR1bxrNK19ZFOqVFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+
          QQIDAQABo4IEXjCCBFowDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUF
          BwMBBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBSQ7QvsgkCU8RgZ
          7rHzBOePjpg0OTAfBgNVHSMEGDAWgBS9BNPD1tr8B9fwyiO3QsgQtKCs2TCCA9kG
          A1UdEQSCA9AwggPMggprdWJlcm5ldGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1
          YmVybmV0ZXMuZGVmYXVsdC5zdmOCHmt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1
          c3RlcoIka3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsghtrdWJl
          cm5ldGVzLm1uY3BsYXltZWRpYS5jb22CG21hbmFnZXItMDEubW5jcGxheW1lZGlh
          LmNvbYIbbWFuYWdlci0wMi5tbmNwbGF5bWVkaWEuY29tghttYW5hZ2VyLTAzLm1u
          Y3BsYXltZWRpYS5jb22CG3dvcmtlci0wMDEubW5jcGxheW1lZGlhLmNvbYIbd29y
          a2VyLTAwMi5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDAzLm1uY3BsYXltZWRp
          YS5jb22CG3dvcmtlci0wMDQubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwNS5t
          bmNwbGF5bWVkaWEuY29tght3b3JrZXItMDA2Lm1uY3BsYXltZWRpYS5jb22CG3dv
          cmtlci0wMDcubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwOC5tbmNwbGF5bWVk
          aWEuY29tght3b3JrZXItMDA5Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTAu
          bW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAxMS5tbmNwbGF5bWVkaWEuY29tght3
          b3JrZXItMDEyLm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTMubW5jcGxheW1l
          ZGlhLmNvbYIbd29ya2VyLTAxNC5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE1
          Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTYubW5jcGxheW1lZGlhLmNvbYIb
          d29ya2VyLTAxNy5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE4Lm1uY3BsYXlt
          ZWRpYS5jb22CG3dvcmtlci0wMTkubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAy
          MC5tbmNwbGF5bWVkaWEuY29thwR/AAABhwQKZAABhwQKCThlhwQKCThmhwQKCThn
          hwQKCThohwQKCThphwQKCThqhwQKCThrhwQKCThshwQKCThthwQKCThuhwQKCThv
          hwQKCThwhwQKCThxhwQKCThyhwQKCThzhwQKCTh0hwQKCTh1hwQKCTh2hwQKCTh3
          hwQKCTh4hwQKCTh5hwQKCTh6hwQKCTh7MA0GCSqGSIb3DQEBCwUAA4IBAQBgIAfQ
          8iygIRCEqj6R//7qHRo506U6QJjxbtveaBhvDR4P5k0V/6t/8RN46NlkWVnT8ghe
          V5Pu0UBaoylhE16Eg2HFrDc4q64zW4WNDePBqWHaQykzOvB2MQLSmqSKWCIv1wvh
          ioaW6VOlNsrF1jKOaN/It9BpGqMzQInU9VHHGoI8Im57zD8qY7NGoPA+2BWcwHfl
          +OO5YWcHib0Z1MbSTewuuRFGAeq6fLr341u7d/K51ycrwC9XrygOvRctAEE4PQNM
          6lvxk7sAwyOXm6WgpE9qwGQw7HrMzRdjNF/XEqmUmylrKNNJCKJiQ/+zWcmAvMyX
          6Ifl783SfZ9Oys72
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/var/lib/etcd/ssl/etcd-node-key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEowIBAAKCAQEAwge2SUSbIB1jHYgHtrpNDaogTbqwjVLWgXJw6yUpzM9cRr7M
          PG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4heuxmKj4AHw/ndNXrb6xiYELuUwE8
          dcrLab2ImnY2YyDE3I30uaUWcgH683pm/GdmGHoLwroyTnoa0b246pAj6eQU4nqe
          H3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QTKtYyCn4uKjmdoN95g8el1rak5D17
          s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6Nx4U5zY8XUns/ArjR1bxrNK19ZFOq
          VFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+QQIDAQABAoIBAHFYJ/gtB6F/CUNb
          D4aC1jhBRZWilTg5R+1eePAkSYLHL1R0aMJ1FP3cGjlalAasBLMI6E+oIpP8Zi5e
          XjI2hYBVUGkkxtVeaQsrW9lkjiNFdgsvEa6NxL4EZiQ1IhhOMDHXCzrXYYE//uT0
          f+y6Sj3KLcyXEIQfeENF3RvJD/G0sOUV0v6xgtO+NN1n0Esw9ffPR7yQ0DdlpWLY
          nbZC2mv+8xjRWaZTFF0GiuBbFDtEBQfDB501bdlypaHcP3Z1hFvutLztnnr3LFpZ
          cJAWYEuN6RPAq6BoMY40sjybSFJcmfO/DC+vChskzMDZLip3lYaAS3n4g2BHJori
          rsLBn/ECgYEAxYj78IQsnpuvqrKVNCoeI0USD4e3g6AiAxrpcYTPIcE5ciwNE9xH
          lplwdyCC/7fLxjh7V/uwU+FhTvqlItGuFUk2moNptin2IfiJ4mXHfzaqDYh6o4Xc
          60exW5Il+8Lkwm08zoHTtX27Gqlp6ycrTIw96q6VnCMCy2aDebM0bGsCgYEA+3Up
          CEAZDSxviBm5bMYBDglmHuPOfeMEVV4NL13uhU6Wk68D+7v6yFvo0WTOcqtybIp7
          7nz2CjF8Fdusp7Sgy49Yrjd0m827tIcEYJR69g1gqlHMzM7CbEujPHsUFrZOEHl5
          /DjTATQuyeovZGYGc9WkJPr61Nw2ejgsn/zFawMCgYEAluICZv3ewyvyK3WLKDQ/
          nvskR36H+192e160D4S9XnAkPARP3Oq2N99uG2BXD5LJcNg1xse2MOwHkvc66fS1
          fwbUUYOtXHqCygH4+Fh74LzVec7UtlEKpSC25VYl8z8z0xrzhl1+Y7PtFflvsTHT
          Df5VUQwXtRK9ELZ2GKB8m48CgYBTSYQUun5RsbUjZDnZgF/bEVvkwVmksqu9xtAh
          L0CQoO4Y7nAoUiQHdwHPUU9cBdN5hgj0filUSP2rk75FMfvMUKdz1ORnsqYIbmwR
          vTxZASdSYpOuBpG5IvhnUPDfcPS8WjAATaX+ERWqRUn7PBvJBCtBIGwyUtoscyy8
          tRGClwKBgGmDGa/fWyI1yS6zp8/pYt7dxQmljCwNPdDecgA3OzqgscGNys+9EQAW
          2oALKiGw0p0zuxx49Wd/9JoBqk+u8Vg2ab9ILnTjjHvYbo3rfDUjTMLERs5/Tmt/
          wQCe4OxmPIOftKJ8kJQuHPI+Mi7cQrhKUGO2RuE21BlSRBnkebjp
          -----END RSA PRIVATE KEY-----
    - filesystem: "root"
      path: "/etc/coredns/tls/etcd/ca.crt"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIEljCCA36gAwIBAgIUU+WUWXU2Eb2mgs7Rr1G0ffEA/IAwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTEw
          MFoXDTI0MDcwMTIzMTEwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAtLFdH094CypU7j6r8ToK
          J+KsLnDw1RNNHb/Qp2+wWailXQ8Haby4QcJKbt1zAwJceNvP6iMFPypp8FB0tIZO
          Icvoq16QkztOnlrg7CMvdutdhlzehefxXFrHaNnekOA/Ss8uvyH7Z5bj7+BmmrtA
          o0jzzh12RS+qIwnBYLgSr01jRKV3F868tPG273Yyb+HaCQTQWXoGfVfiT1va6zB/
          IEXlWt/K0FmM7uMyVPlAlxq214NSdaEz+e8qORuLp5EhZp58cwSotLxAcdYdRurI
          yPnGwZ4cjvTg97FH55fhQ+x7jkSXs09Hbq95yEtBJ9RWL83SHr2mckIQM+MSzJel
          qwIDAQABo4IBDDCCAQgwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8C
          AQIwHQYDVR0OBBYEFL0E08PW2vwH1/DKI7dCyBC0oKzZMB8GA1UdIwQYMBaAFL0E
          08PW2vwH1/DKI7dCyBC0oKzZMIGhBgNVHREEgZkwgZaHBH8AAAGHBApkAAGHBAoJ
          OGWHBAoJOGaHBAoJOGeHBAoJOGiHBAoJOGmHBAoJOGqHBAoJOGuHBAoJOGyHBAoJ
          OG2HBAoJOG6HBAoJOG+HBAoJOHCHBAoJOHGHBAoJOHKHBAoJOHOHBAoJOHSHBAoJ
          OHWHBAoJOHaHBAoJOHeHBAoJOHiHBAoJOHmHBAoJOHqHBAoJOHswDQYJKoZIhvcN
          AQELBQADggEBADYGbExdzqhRXOdFSNswme8w61qiMfdEDYfiqk1VnEiU5A8jCeZe
          AeTt5LJHhxVh5uu6LiGzBQPbLahF9MrBw0dty4f85NugN2dca/gUxy70GjHeZatS
          WpTthLV9vQ0SU6tgzT4tItzInK0o7jev10IEcgqozoG2Tj3f0CwBnj72moz1681B
          zwfAn3RhmqiVU9uh1tyXFfqTcfVHq4f/Qj/+F5621VbNWFQwkypy27O4SyRYM0b9
          wWsxCXXfQPCTVcd69XRu4dKWhL7X9z+0CGkeEFwE515pYzcOB1dWnTDo+DW2g6av
          S8utxK8/C4qecEL3p4DLqHwMgpKl/89L0JI=
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/coredns/tls/etcd/cert.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN CERTIFICATE-----
          MIIH6DCCBtCgAwIBAgIULy3KnguWZtIbB2ugQjgRjyct9YIwDQYJKoZIhvcNAQEL
          BQAwfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdvbjERMA8GA1UEBxMIUG9y
          dGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNVBAsTF0t1YmVybmV0ZXMg
          VGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE5MDcwMzIzMTYw
          MFoXDTI5MDYzMDIzMTYwMFowfTELMAkGA1UEBhMCVVMxDzANBgNVBAgTBk9yZWdv
          bjERMA8GA1UEBxMIUG9ydGxhbmQxEzARBgNVBAoTCkt1YmVybmV0ZXMxIDAeBgNV
          BAsTF0t1YmVybmV0ZXMgVGhlIEhhcmQgV2F5MRMwEQYDVQQDEwprdWJlcm5ldGVz
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwge2SUSbIB1jHYgHtrpN
          DaogTbqwjVLWgXJw6yUpzM9cRr7MPG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4h
          euxmKj4AHw/ndNXrb6xiYELuUwE8dcrLab2ImnY2YyDE3I30uaUWcgH683pm/Gdm
          GHoLwroyTnoa0b246pAj6eQU4nqeH3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QT
          KtYyCn4uKjmdoN95g8el1rak5D17s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6N
          x4U5zY8XUns/ArjR1bxrNK19ZFOqVFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+
          QQIDAQABo4IEXjCCBFowDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUF
          BwMBBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBSQ7QvsgkCU8RgZ
          7rHzBOePjpg0OTAfBgNVHSMEGDAWgBS9BNPD1tr8B9fwyiO3QsgQtKCs2TCCA9kG
          A1UdEQSCA9AwggPMggprdWJlcm5ldGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1
          YmVybmV0ZXMuZGVmYXVsdC5zdmOCHmt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1
          c3RlcoIka3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsghtrdWJl
          cm5ldGVzLm1uY3BsYXltZWRpYS5jb22CG21hbmFnZXItMDEubW5jcGxheW1lZGlh
          LmNvbYIbbWFuYWdlci0wMi5tbmNwbGF5bWVkaWEuY29tghttYW5hZ2VyLTAzLm1u
          Y3BsYXltZWRpYS5jb22CG3dvcmtlci0wMDEubW5jcGxheW1lZGlhLmNvbYIbd29y
          a2VyLTAwMi5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDAzLm1uY3BsYXltZWRp
          YS5jb22CG3dvcmtlci0wMDQubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwNS5t
          bmNwbGF5bWVkaWEuY29tght3b3JrZXItMDA2Lm1uY3BsYXltZWRpYS5jb22CG3dv
          cmtlci0wMDcubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAwOC5tbmNwbGF5bWVk
          aWEuY29tght3b3JrZXItMDA5Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTAu
          bW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAxMS5tbmNwbGF5bWVkaWEuY29tght3
          b3JrZXItMDEyLm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTMubW5jcGxheW1l
          ZGlhLmNvbYIbd29ya2VyLTAxNC5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE1
          Lm1uY3BsYXltZWRpYS5jb22CG3dvcmtlci0wMTYubW5jcGxheW1lZGlhLmNvbYIb
          d29ya2VyLTAxNy5tbmNwbGF5bWVkaWEuY29tght3b3JrZXItMDE4Lm1uY3BsYXlt
          ZWRpYS5jb22CG3dvcmtlci0wMTkubW5jcGxheW1lZGlhLmNvbYIbd29ya2VyLTAy
          MC5tbmNwbGF5bWVkaWEuY29thwR/AAABhwQKZAABhwQKCThlhwQKCThmhwQKCThn
          hwQKCThohwQKCThphwQKCThqhwQKCThrhwQKCThshwQKCThthwQKCThuhwQKCThv
          hwQKCThwhwQKCThxhwQKCThyhwQKCThzhwQKCTh0hwQKCTh1hwQKCTh2hwQKCTh3
          hwQKCTh4hwQKCTh5hwQKCTh6hwQKCTh7MA0GCSqGSIb3DQEBCwUAA4IBAQBgIAfQ
          8iygIRCEqj6R//7qHRo506U6QJjxbtveaBhvDR4P5k0V/6t/8RN46NlkWVnT8ghe
          V5Pu0UBaoylhE16Eg2HFrDc4q64zW4WNDePBqWHaQykzOvB2MQLSmqSKWCIv1wvh
          ioaW6VOlNsrF1jKOaN/It9BpGqMzQInU9VHHGoI8Im57zD8qY7NGoPA+2BWcwHfl
          +OO5YWcHib0Z1MbSTewuuRFGAeq6fLr341u7d/K51ycrwC9XrygOvRctAEE4PQNM
          6lvxk7sAwyOXm6WgpE9qwGQw7HrMzRdjNF/XEqmUmylrKNNJCKJiQ/+zWcmAvMyX
          6Ifl783SfZ9Oys72
          -----END CERTIFICATE-----
    - filesystem: "root"
      path: "/etc/coredns/tls/etcd/key.pem"
      mode: 0644
      contents:
        inline: |
          -----BEGIN RSA PRIVATE KEY-----
          MIIEowIBAAKCAQEAwge2SUSbIB1jHYgHtrpNDaogTbqwjVLWgXJw6yUpzM9cRr7M
          PG9Ru7G8yxlP9N+T7xRgj+eDpt7f11/QLe4heuxmKj4AHw/ndNXrb6xiYELuUwE8
          dcrLab2ImnY2YyDE3I30uaUWcgH683pm/GdmGHoLwroyTnoa0b246pAj6eQU4nqe
          H3wBWvIUW1ts4Xj92XwA0IaLzFEKL5vFY3QTKtYyCn4uKjmdoN95g8el1rak5D17
          s0mMJu3B123ARY8eKSuZzJB0ULHOe/TwGO6Nx4U5zY8XUns/ArjR1bxrNK19ZFOq
          VFZE7QSqmVzNJ8C+T1v2bYr3mHM5z6TZxUT+QQIDAQABAoIBAHFYJ/gtB6F/CUNb
          D4aC1jhBRZWilTg5R+1eePAkSYLHL1R0aMJ1FP3cGjlalAasBLMI6E+oIpP8Zi5e
          XjI2hYBVUGkkxtVeaQsrW9lkjiNFdgsvEa6NxL4EZiQ1IhhOMDHXCzrXYYE//uT0
          f+y6Sj3KLcyXEIQfeENF3RvJD/G0sOUV0v6xgtO+NN1n0Esw9ffPR7yQ0DdlpWLY
          nbZC2mv+8xjRWaZTFF0GiuBbFDtEBQfDB501bdlypaHcP3Z1hFvutLztnnr3LFpZ
          cJAWYEuN6RPAq6BoMY40sjybSFJcmfO/DC+vChskzMDZLip3lYaAS3n4g2BHJori
          rsLBn/ECgYEAxYj78IQsnpuvqrKVNCoeI0USD4e3g6AiAxrpcYTPIcE5ciwNE9xH
          lplwdyCC/7fLxjh7V/uwU+FhTvqlItGuFUk2moNptin2IfiJ4mXHfzaqDYh6o4Xc
          60exW5Il+8Lkwm08zoHTtX27Gqlp6ycrTIw96q6VnCMCy2aDebM0bGsCgYEA+3Up
          CEAZDSxviBm5bMYBDglmHuPOfeMEVV4NL13uhU6Wk68D+7v6yFvo0WTOcqtybIp7
          7nz2CjF8Fdusp7Sgy49Yrjd0m827tIcEYJR69g1gqlHMzM7CbEujPHsUFrZOEHl5
          /DjTATQuyeovZGYGc9WkJPr61Nw2ejgsn/zFawMCgYEAluICZv3ewyvyK3WLKDQ/
          nvskR36H+192e160D4S9XnAkPARP3Oq2N99uG2BXD5LJcNg1xse2MOwHkvc66fS1
          fwbUUYOtXHqCygH4+Fh74LzVec7UtlEKpSC25VYl8z8z0xrzhl1+Y7PtFflvsTHT
          Df5VUQwXtRK9ELZ2GKB8m48CgYBTSYQUun5RsbUjZDnZgF/bEVvkwVmksqu9xtAh
          L0CQoO4Y7nAoUiQHdwHPUU9cBdN5hgj0filUSP2rk75FMfvMUKdz1ORnsqYIbmwR
          vTxZASdSYpOuBpG5IvhnUPDfcPS8WjAATaX+ERWqRUn7PBvJBCtBIGwyUtoscyy8
          tRGClwKBgGmDGa/fWyI1yS6zp8/pYt7dxQmljCwNPdDecgA3OzqgscGNys+9EQAW
          2oALKiGw0p0zuxx49Wd/9JoBqk+u8Vg2ab9ILnTjjHvYbo3rfDUjTMLERs5/Tmt/
          wQCe4OxmPIOftKJ8kJQuHPI+Mi7cQrhKUGO2RuE21BlSRBnkebjp
          -----END RSA PRIVATE KEY-----